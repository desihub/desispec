#!/usr/bin/env python
#
# See top-level LICENSE.rst file for Copyright information
#
# -*- coding: utf-8 -*-

"""
Setup pipeline reduction from scratch
"""

from __future__ import absolute_import, division, print_function

import sys
import os
import numpy as np
import argparse
import re
import subprocess as sp

import desispec.io as io

import desispec.pipeline as pipe


def main():
    parser = argparse.ArgumentParser(description='Set up pipeline runs for a production.')
    parser.add_argument('--raw', required=False, default=None, help='raw data directory')
    parser.add_argument('--redux', required=False, default=None, help='output directory')
    parser.add_argument('--prod', required=False, default='test', help='output production name')
    parser.add_argument('--nights', required=False, default=None, help='comma separated (YYYYMMDD) or regex pattern')
    
    parser.add_argument('--env', required=False, default=None, help='text file with environment setup commands')
    
    parser.add_argument('--nersc_host', required=False, default='edison', help='NERSC slurm scripts host name (edison|cori)')

    parser.add_argument('--nersc_max_proc', required=False, default='edison', help='NERSC slurm scripts max processes to use.  Default is size of debug queue max.')

    parser.add_argument('--shell_mpi_run', required=False, default='mpirun -np', help='bash scripts command to launch MPI pipeline steps.  If --shell_max_proc is 1, this is ignored.')
    parser.add_argument('--shell_max_proc', required=False, default=2, help='bash scripts max processes to use.')

    parser.add_argument('--fakeboot', required=False, default=None, help='path to input psf-{r,b,z}.fits files, to bypass bootcalib')
    parser.add_argument('--spectrographs', required=False, default=None, help='process only this comma-separated list of spectrographs')

    args = parser.parse_args()

    nodecores = 0
    if args.nerschost == 'edison':
        nodecores = 24
    elif args.nerschost == 'cori':
        nodecores = 32
    else:
        raise RuntimeError("unknown nersc host")

    shell_nproc = int(args.shell_max_proc)
    shell_run = ""
    if shell_nproc > 1:
        shell_run = "{} {}".format(args.shell_mpi_run, shell_nproc)

    frames_per_exp = 3 * len(spectrographs)

    rawdir = args.raw
    if rawdir is None:
        rawdir = io.rawdata_root()
    rawdir = os.path.abspath(rawdir)

    specdir = args.redux
    if specdir is None:
        specdir = io.specprod_root()
    specdir = os.path.abspath(specdir)

    # Update output directories and plans

    print("Updating production {}".format(proddir))
    pipe.create_prod(rawdir, proddir, nightstr=args.nights)

    # create setup shell snippet

    setupfile = os.path.abspath(os.path.join(proddir, 'setup.sh'))
    with open(setupfile, 'w') as s:
        s.write("# Generated by desi_pipe\n")
        s.write("export DESI_SPECTRO_DATA={}\n".format(rawdir))
        s.write("export DESI_SPECTRO_REDUX={}\n".format(specdir))
        s.write("export PRODNAME={}\n".format(args.prod))
        s.write("\n")

    # load those same things into the environment.

    os.environ['DESI_SPECTRO_DATA'] = rawdir
    os.environ['DESI_SPECTRO_REDUX'] = specdir
    os.environ['PRODNAME'] = args.prod

    # read in the environment setup, if needed

    envcom = []
    if args.env is not None:
        with open(args.env, 'r') as f:
            for line in f:
                envcom.append(line.rstrip())

    # create scripts for processing

    print("Generating scripts")

    scrdir = os.path.join(proddir, 'run', 'scripts')
    logdir = os.path.join(proddir, 'run', 'logs')

    specstr = ""
    nspect = 10
    if args.spectrographs is not None:
        specstr = "--spectrographs {}".format(args.spectrographs)
        nspect = len(args.spectrographs.split(','))

    # bootcalib

    if args.fakeboot is None:
        com_full = ["desi_pipe_run --first bootcalib --last bootcalib {}".format(specstr)]

        shell_path = os.path.join(scrdir, "bootcalib_all.sh")
        shell_log = os.path.join(logdir, "bootcalib_all")
        pipe.shell_job(shell_path, shell_log, envcom, setupfile, shell_run, com_full)

        nersc_path = os.path.join(scrdir, "bootcalib_all.slurm")
        nersc_log = os.path.join(logdir, "bootcalib_all")

        tot_tasks = 

        pipe.nersc_job(nersc_path, nersc_log, envcom, setupfile, com_full, nodes=1, nodeproc=1, minutes=30, multisrun=True, openmp=False, multiproc=False)


pipe.nersc_job(path, logroot, envsetup, desisetup, commands, nodes=1, nodeproc=1, minutes=10, multisrun=False, openmp=False, multiproc=False)

    for nt in nights:

        # bootcalib

        

            com = []
            com.append("desi_pipe_run --first bootcalib --last bootcalib --nights {} --")


        else:
            cal2d = os.path.join(proddir, 'calib2d')
            calpsf = os.path.join(cal2d, 'psf')
            calpsfnight = os.path.join(calpsf, nt)
            if not os.path.isdir(calpsfnight):
                os.makedirs(calpsfnight)

            for band in ['b', 'r', 'z']:
                for spec in range(10):
                    cam = "{}{}".format(band, spec)
                    target = os.path.join(os.environ['DESIMODEL'], 'data', 'specpsf', "psf-{}.fits".format(band))
                    lnk = os.path.join(calpsfnight, "psfboot-{}{}.fits".format(band, spec))
                    if not os.path.islink(lnk):
                        os.symlink(target, lnk)














        # get the list of exposures and their types
        (expid, exptype, fibermaps, fullraw) = pipe.find_raw(rawdir, nt, spectrographs=spectrographs)

        print("Night {}:".format(nt))

        allarcs = []
        allflats = []
        allscience = []
        for ex in expid:
            if exptype[ex] == "arc":
                allarcs.append(ex)
                print("  {:08d} : arc".format(ex))
            elif exptype[ex] == "flat":
                allflats.append(ex)
                print("  {:08d} : flat".format(ex))
            else:
                allscience.append(ex)
                print("  {:08d} : science".format(ex))

        if len(allarcs) == 0:
            raise RuntimeError("night {} has no calibration exposures".format(nt))
        if len(allflats) == 0:
            raise RuntimeError("night {} has no flats".format(nt))
        if len(allscience) == 0:
            raise RuntimeError("night {} has no science exposures".format(nt))
        
        # make nightly script and log directories
        nsdir = os.path.join(scrdir, nt)
        if not os.path.isdir(nsdir):
            os.makedirs(nsdir)
        nldir = os.path.join(logdir, nt)
        if not os.path.isdir(nldir):
            os.makedirs(nldir)

        # create scripts to run bootcalib
        if args.fakeboot is not None:
            for band in ['b', 'r', 'z']:
                truepsf = os.path.join(args.fakeboot, "psf-{}.fits".format(band))
                for spec in spectrographs:
                    lnk = os.path.join(calpsf, nt, "psfboot-{}{}.fits".format(band, spec))
                    if not os.path.islink(lnk):
                        os.symlink(truepsf, lnk)
        else:
            firstarc = allarcs[0]
            firstflat = allflats[0]
            commands = []
            for cam in sorted(fullraw[firstarc].keys()):
                spc = int(cam[1])
                if spc in spectrographs:
                    flatname = "{}-{}-{:08d}.fits".format(pixroot, cam, firstflat)
                    flatfile = os.path.join(rawdir, nt, flatname)
                    arcname = "{}-{}-{:08d}.fits".format(pixroot, cam, firstarc)
                    arcfile = os.path.join(rawdir, nt, arcname)
                    outname = "psfboot-{}.fits".format(cam)
                    outfile = os.path.join(calpsf, nt, outname)
                    commands.append("desi_bootcalib --triplet-matching --legendre-degree 5 --fiberflat {} --arcfile {} --outfile {}".format(flatfile, arcfile, outfile))
            shell_file = os.path.join(nsdir, "bootcalib.sh")
            nersc_file = os.path.join(nsdir, "bootcalib.nersc")
            shell_log = os.path.join(nldir, "bootcalib_sh")
            nersc_log = os.path.join(nldir, "bootcalib_nersc")
            pipe.shell_job(shell_file, shell_log, envcom, setupfile, commands)
            pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, commands, nodes=1, nodeproc=1, minutes=30, multisrun=True, openmp=False, multiproc=False)

            com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run specex

        #lamplines = "/project/projectdirs/desi/software/edison/specex/specex-0.3.4/data/lamplines-specex.par"
        lamplines = "/project/projectdirs/desi/software/edison/specex/specex-0.3.9/data/specex_linelist_boss.txt"

        shell_file = os.path.join(nsdir, "specex.sh")
        nersc_file = os.path.join(nsdir, "specex.nersc")
        dump_file = os.path.join(nsdir, "specex_commands.txt")
        shell_log = os.path.join(nldir, "specex_sh")
        nersc_log = os.path.join(nldir, "specex_nersc")

        comopts = "--lamplines {} --night {} --spectrographs {}".format(lamplines, nt, spectrostr)
        
        complan = "desi_plan_psf {} --dump {}".format(comopts, dump_file)
        #spret = sp.call(complan, shell=True)

        com = "desi_pipe_psf {}".format(comopts)

        pipe.shell_job(shell_file, shell_log, envcom, setupfile, [com])

        # we want to use enough nodes to run one exposure simultaneously.
        nbundle = len(allarcs) * frames_per_exp * 20
        nodeproc = 8
        runnodes = int(nbundle / nodeproc)
        if runnodes * nodeproc != nbundle:
            runnodes += 1
        # for one exposure, there are 600 bundles.  If we run 8 per node
        # (which works well for 24 or 32 cores per node), then we want 
        # 75 nodes.  Specex is OpenMP parallel.
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, [com], nodes=runnodes, nodeproc=nodeproc, minutes=30, openmp=True, multiproc=False)

        com_master_shell.append("bash {}".format(shell_file))

        # Create script to generate best psf

        commands = []
        for cam in sorted(fullraw[allarcs[0]].keys()):
            outname = "psf-{}.fits".format(cam)
            outfile = os.path.join(calpsf, nt, outname)
            infiles = []
            for arc in allarcs:
                spc = int(cam[1])
                if spc in spectrographs:
                    psfname = "psf-{}-{:08d}.fits".format(cam, arc)
                    psffile = os.path.join(expdir, nt, "{:08d}".format(arc), psfname)
                    infiles.append(psffile)
            commands.append("specex_mean_psf --output {} --input {}".format(outfile, " ".join(infiles)))
        
        shell_file = os.path.join(nsdir, "meanpsf.sh")
        nersc_file = os.path.join(nsdir, "meanpsf.nersc")
        shell_log = os.path.join(nldir, "meanpsf_sh")
        nersc_log = os.path.join(nldir, "meanpsf_nersc")
        pipe.shell_job(shell_file, shell_log, envcom, setupfile, commands)
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, commands, nodes=1, nodeproc=1, minutes=10, multisrun=True, openmp=False, multiproc=False)

        com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run exspec

        shell_file = os.path.join(nsdir, "exspec.sh")
        nersc_file = os.path.join(nsdir, "exspec.nersc")
        dump_file = os.path.join(nsdir, "exspec_commands.txt")
        shell_log = os.path.join(nldir, "exspec_sh")
        nersc_log = os.path.join(nldir, "exspec_nersc")

        comopts = "--night {} --spectrographs {}".format(nt, spectrostr)
        
        complan = "desi_plan_extract {} --dump {}".format(comopts, dump_file)
        #spret = sp.call(complan, shell=True)

        com = "desi_pipe_extract {}".format(comopts)
        
        pipe.shell_job(shell_file, shell_log, envcom, setupfile, [com])
        # we want to run all tasks at once.  we use one core per task.
        nbundle = (len(allscience) + len(allflats)) * frames_per_exp * 20
        nodeproc = 8
        runnodes = int(nbundle / nodeproc)
        if runnodes * nodeproc != nbundle:
            runnodes += 1
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, [com], nodes=runnodes, nodeproc=nodeproc, minutes=30, openmp=False, multiproc=True)

        com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run calibration

        shell_file = os.path.join(nsdir, "calib.sh")
        nersc_file = os.path.join(nsdir, "calib.nersc")
        dump_file = os.path.join(nsdir, "calib_commands.txt")
        shell_log = os.path.join(nldir, "calib_sh")
        nersc_log = os.path.join(nldir, "calib_nersc")

        comopts = "--night {}".format(nt)
        
        complan = "desi_plan_calib {} --dump {}".format(comopts, dump_file)
        #spret = sp.call(complan, shell=True)

        com = "desi_pipe_calib {}".format(comopts)

        pipe.shell_job(shell_file, shell_log, envcom, setupfile, [com])
        # fiberflat is much more expensive than the other steps.
        # so we use the number of flats to set the concurrency.
        nframe = len(allflats) * frames_per_exp
        nodeproc = nodecores
        runnodes = int(nframe / nodeproc)
        if runnodes * nodeproc != nframe:
            runnodes += 1
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, [com], nodes=runnodes, nodeproc=nodeproc, minutes=30, openmp=False, multiproc=True)

        com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run make bricks

        commands = []
        commands.append("desi_make_bricks --night {}".format(nt))
        shell_file = os.path.join(nsdir, "bricks.sh")
        nersc_file = os.path.join(nsdir, "bricks.nersc")
        shell_log = os.path.join(nldir, "bricks_sh")
        nersc_log = os.path.join(nldir, "bricks_nersc")
        pipe.shell_job(shell_file, shell_log, envcom, setupfile, commands)
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, commands, nodes=1, nodeproc=1, minutes=30, openmp=False, multiproc=False)

        com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run zfind

        shell_file = os.path.join(nsdir, "zfind.sh")
        nersc_file = os.path.join(nsdir, "zfind.nersc")
        dump_file = os.path.join(nsdir, "zfind_commands.txt")
        shell_log = os.path.join(nldir, "zfind_sh")
        nersc_log = os.path.join(nldir, "zfind_nersc")
        
        complan = "desi_plan_zfind --dump {}".format(dump_file)
        #spret = sp.call(complan, shell=True)

        com = "desi_pipe_zfind"

        pipe.shell_job(shell_file, shell_log, envcom, setupfile, [com])

        # one process per node for each brick
        nbricks = len(pipe.get_fibermap_bricknames(fibermaps.values()))
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, [com], nodes=nbricks, nodeproc=1, minutes=30, openmp=False, multiproc=True)

        com_master_shell.append("bash {}".format(shell_file))

    # Create master scripts with job dependencies
    shell_master = os.path.join(scrdir, 'run.sh')
    with open(shell_master, 'w') as f:
        for com in com_master_shell:
            f.write("{}\n".format(com))

    shell_nersc = os.path.join(scrdir, 'run.nersc')
    with open(shell_nersc, 'w') as f:
        for com in com_master_nersc:
            f.write("{}\n".format(com))


if __name__ == "__main__":
    main()

