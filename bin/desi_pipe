#!/usr/bin/env python
#
# See top-level LICENSE.rst file for Copyright information
#
# -*- coding: utf-8 -*-

"""
Setup pipeline reduction from scratch
"""

from __future__ import absolute_import, division, print_function

import sys
import os
import numpy as np
import argparse
import re
import subprocess as sp

import desispec.io as io

import desispec.pipeline as pipe


def compute_step(setupfile, rawdir, proddir, envcom, first, last, specs, night, ntask, taskproc, shell_mpi_run, shell_maxcores, shell_threads, nersc_maxnodes, nersc_nodecores, nersc_threads, nersc_mp, nersc_queue_thresh):
    specstr = ""
    if specs is not None:
        specstr = " --spectrographs {}".format(','.join([ "{}".format(x) for x in specs ]))

    scrdir = os.path.join(proddir, 'run', 'scripts')
    logdir = os.path.join(proddir, 'run', 'logs')

    if (nersc_threads > 1) and (nersc_mp > 1):
        raise RuntimeError("set either nersc_threads or nersc_mp, but not both")

    nstr = ""
    scrstr = "all"
    if night is not None:
        nstr = " --nights {}".format(night)
        scrstr = "{}".format(night)

    stepstr = "{}-{}_{}".format(first, last, scrstr)
    if first == last:
        stepstr = "{}_{}".format(first, scrstr)

    com = ["desi_pipe_run --first {} --last {}{}{}".format(first, last, specstr, nstr)]

    totproc = ntask * taskproc

    shell_maxprocs = int(shell_maxcores / shell_threads)
    shell_procs = shell_maxprocs
    if totproc < shell_procs:
        shell_procs = totproc

    shell_path = os.path.join(scrdir, "{}.sh".format(stepstr))
    shell_log = os.path.join(logdir, "{}_sh".format(stepstr))
    pipe.shell_job(shell_path, shell_log, envcom, setupfile, com, comrun=shell_mpi_run, mpiprocs=shell_procs, threads=shell_threads)

    core_per_proc = 1
    if nersc_threads > 1:
        core_per_proc = nersc_threads
    elif nersc_mp > 1:
        core_per_proc = nersc_mp

    nodeproc = int(nersc_nodecores / core_per_proc)
    nodes = int(totproc / nodeproc)
    if nodes * nodeproc != totproc:
        nodes += 1
    if nodes > nersc_maxnodes:
        nodes = nersc_maxnodes

    queue = 'debug'
    if nodes > nersc_queue_thresh:
        queue = 'regular'

    nersc_path = os.path.join(scrdir, "{}.slurm".format(stepstr))
    nersc_log = os.path.join(logdir, "{}_slurm".format(stepstr))

    pipe.nersc_job(nersc_path, nersc_log, envcom, setupfile, com, nodes=nodes, nodeproc=nodeproc, minutes=30, multisrun=False, openmp=(nersc_threads > 1), multiproc=(nersc_mp > 1), queue=queue)

    return


def main():
    parser = argparse.ArgumentParser(description='Set up pipeline runs for a production.')
    parser.add_argument('--raw', required=False, default=None, help='raw data directory')
    parser.add_argument('--redux', required=False, default=None, help='output directory')
    parser.add_argument('--prod', required=False, default='test', help='output production name')
    parser.add_argument('--nights', required=False, default=None, help='comma separated (YYYYMMDD) or regex pattern')
    
    parser.add_argument('--env', required=False, default=None, help='text file with environment setup commands')
    
    parser.add_argument('--nersc_host', required=False, default='edison', help='NERSC slurm scripts host name (edison|cori)')

    parser.add_argument('--nersc_max_nodes', required=False, default=None, help='NERSC slurm scripts max nodes to use.  Default is size of debug queue max.')

    parser.add_argument('--shell_mpi_run', required=False, default='mpirun -np', help='bash scripts command to launch MPI pipeline steps.  If --shell_max_cores is 1, this is ignored.')
    parser.add_argument('--shell_max_cores', required=False, default=2, help='bash scripts max cores to use.')

    parser.add_argument('--fakeboot', required=False, default=False, action="store_true", help='bypass bootcalib')

    parser.add_argument('--fakepsf', required=False, default=False, action="store_true", help='bypass specex')

    parser.add_argument('--spectrographs', required=False, default=None, help='process only this comma-separated list of spectrographs')

    parser.add_argument('--zfind_workers', required=False, default=20, help='number of zfind workers.')

    args = parser.parse_args()

    nodecores = 0
    maxnodes = 0
    if args.nersc_host == 'edison':
        nodecores = 24
        if args.nersc_max_nodes is not None:
            maxnodes = int(args.nersc_max_nodes)
        else:
            maxnodes = 512
    elif args.nerschost == 'cori':
        nodecores = 32
        if args.nersc_max_nodes is not None:
            maxnodes = int(args.nersc_max_nodes)
        else:
            maxnodes = 64
    else:
        raise RuntimeError("unknown nersc host")

    shell_maxcores = int(args.shell_max_cores)
    shell_mpi_run = ""
    if shell_maxcores > 1:
        shell_mpi_run = "{}".format(args.shell_mpi_run)

    rawdir = args.raw
    if rawdir is None:
        rawdir = io.rawdata_root()
    rawdir = os.path.abspath(rawdir)

    specdir = args.redux
    if specdir is None:
        if 'DESI_SPECTRO_REDUX' not in os.environ:
            raise RuntimeError("You must set DESI_SPECTRO_REDUX in your environment or with a commandline option")
        specdir = os.path.abspath(os.environ['DESI_SPECTRO_REDUX'])
    specdir = os.path.abspath(specdir)

    prodname = args.prod
    if prodname is None:
        if 'PRODNAME' not in os.environ:
            raise RuntimeError("You must set PRODNAME in your environment or with a commandline option")
        prodname = os.environ['PRODNAME']

    proddir = os.path.join(specdir, prodname)

    # Update output directories and plans

    print("Updating production {}".format(proddir))
    expnightcount = pipe.create_prod(rawdir, proddir, nightstr=args.nights)
    totcount = {}
    totcount['flat'] = 0
    totcount['arc'] = 0
    totcount['science'] = 0
    for k, v in expnightcount.items():
        totcount['flat'] += v['flat']
        totcount['arc'] += v['arc']
        totcount['science'] += v['science']

    # create setup shell snippet

    setupfile = os.path.abspath(os.path.join(proddir, 'setup.sh'))
    with open(setupfile, 'w') as s:
        s.write("# Generated by desi_pipe\n")
        s.write("export DESI_SPECTRO_DATA={}\n".format(rawdir))
        s.write("export DESI_SPECTRO_REDUX={}\n".format(specdir))
        s.write("export PRODNAME={}\n".format(prodname))
        s.write("\n")

    # load those same things into the environment.

    os.environ['DESI_SPECTRO_DATA'] = rawdir
    os.environ['DESI_SPECTRO_REDUX'] = specdir
    os.environ['PRODNAME'] = prodname

    # read in the environment setup, if needed

    envcom = []
    if args.env is not None:
        with open(args.env, 'r') as f:
            for line in f:
                envcom.append(line.rstrip())

    # which nights and spectrographs are we using?

    specs = [ x for x in range(10) ]
    if args.spectrographs is not None:
        specs = [ int(x) for x in args.spectrographs.split(',') ]
    nspect = len(specs)

    allnights = []
    nightpat = re.compile(r'\d{8}')
    for root, dirs, files in os.walk(rawdir, topdown=True):
        for d in dirs:
            nightmat = nightpat.match(d)
            if nightmat is not None:
                allnights.append(d)
        break

    nights = pipe.select_nights(allnights, args.nights)

    # create scripts for processing

    print("Generating scripts")

    # bootcalib

    if not args.fakeboot:

        ntask = len(nights) * 3 * nspect
        taskproc = 1
        multip = 3

        compute_step(setupfile, rawdir, proddir, envcom, "bootcalib", "bootcalib", specs, None, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, 1, multip, maxnodes)

        for nt in nights:

            ntask = 3 * nspect

            compute_step(setupfile, rawdir, proddir, envcom, "bootcalib", "bootcalib", specs, nt, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, 1, multip, maxnodes)

    else:

        cal2d = os.path.join(proddir, 'calib2d')
        calpsf = os.path.join(cal2d, 'psf')

        for nt in nights:

            calpsfnight = os.path.join(calpsf, nt)
            if not os.path.isdir(calpsfnight):
                os.makedirs(calpsfnight)

            for band in ['b', 'r', 'z']:
                for spec in range(10):
                    cam = "{}{}".format(band, spec)
                    target = os.path.join(os.environ['DESIMODEL'], 'data', 'specpsf', "psf-{}.fits".format(band))
                    lnk = os.path.join(calpsfnight, "psfboot-{}{}.fits".format(band, spec))
                    if not os.path.islink(lnk):
                        os.symlink(target, lnk)

    # specex

    if not args.fakepsf:

        ntask = totcount['arc'] * 3 * nspect
        taskproc = 20
        threads = 3

        compute_step(setupfile, rawdir, proddir, envcom, "specex", "specex", specs, None, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, threads, 1, maxnodes)

        for nt in nights:

            ntask = expnightcount[nt]['arc'] * 3 * nspect

            compute_step(setupfile, rawdir, proddir, envcom, "specex", "specex", specs, nt, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, threads, 1, maxnodes)

        # psfcombine

        ntask = len(nights) * 3 * nspect
        taskproc = 1

        compute_step(setupfile, rawdir, proddir, envcom, "psfcombine", "psfcombine", specs, None, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, 1, 1, maxnodes)

        for nt in nights:

            ntask = 3 * nspect

            compute_step(setupfile, rawdir, proddir, envcom, "psfcombine", "psfcombine", specs, nt, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, 1, 1, maxnodes)

    else:

        cal2d = os.path.join(proddir, 'calib2d')
        calpsf = os.path.join(cal2d, 'psf')

        for nt in nights:

            calpsfnight = os.path.join(calpsf, nt)
            if not os.path.isdir(calpsfnight):
                os.makedirs(calpsfnight)

            for band in ['b', 'r', 'z']:
                for spec in range(10):
                    cam = "{}{}".format(band, spec)
                    target = os.path.join(calpsfnight, "psfboot-{}{}.fits".format(band, spec))
                    lnk = os.path.join(calpsfnight, "psfnight-{}{}.fits".format(band, spec))
                    if not os.path.islink(lnk):
                        os.symlink(target, lnk)

    # extract

    ntask = (totcount['flat'] + totcount['science']) * 3 * nspect
    taskproc = 20
    threads = 3

    compute_step(setupfile, rawdir, proddir, envcom, "extract", "extract", specs, None, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, threads, 1, maxnodes)

    for nt in nights:

        ntask = (expnightcount[nt]['flat'] + expnightcount[nt]['science']) * 3 * nspect

        compute_step(setupfile, rawdir, proddir, envcom, "extract", "extract", specs, nt, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, threads, 1, maxnodes)

    # calibration

    ntask = totcount['science'] * 3 * nspect
    taskproc = 1
    multip = 3

    compute_step(setupfile, rawdir, proddir, envcom, "fiberflat", "procexp", specs, None, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, 1, multip, maxnodes)

    for nt in nights:

        ntask = expnightcount[nt]['science'] * 3 * nspect

        compute_step(setupfile, rawdir, proddir, envcom, "fiberflat", "procexp", specs, nt, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, 1, multip, maxnodes)

    # make bricks - serial only for now!

    scrdir = os.path.join(proddir, 'run', 'scripts')
    logdir = os.path.join(proddir, 'run', 'logs')

    brickcom = []
    for nt in nights:
        brickcom.append("desi_make_bricks --night {}".format(nt))

    shell_path = os.path.join(scrdir, "bricks.sh")
    shell_log = os.path.join(logdir, "bricks_sh.log")
    pipe.shell_job(shell_path, shell_log, envcom, setupfile, brickcom, comrun=shell_mpi_run, mpiprocs=1, threads=1)

    nersc_path = os.path.join(scrdir, "bricks.slurm")
    nersc_log = os.path.join(logdir, "bricks_slurm.log")
    pipe.nersc_job(nersc_path, nersc_log, envcom, setupfile, brickcom, nodes=1, nodeproc=1, minutes=30, multisrun=False, openmp=False, multiproc=False, queue='debug')

    # redshift fitting

    ntask = int(args.zfind_workers)
    taskproc = 1

    compute_step(setupfile, rawdir, proddir, envcom, "zfind", "zfind", specs, None, ntask, taskproc, shell_mpi_run, shell_maxcores, 1, maxnodes, nodecores, 1, nodecores, maxnodes)




if __name__ == "__main__":
    main()

