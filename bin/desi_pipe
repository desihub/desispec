#!/usr/bin/env python
#
# See top-level LICENSE.rst file for Copyright information
#
# -*- coding: utf-8 -*-

"""
Setup pipeline reduction from scratch
"""

from __future__ import absolute_import, division, print_function

import sys
import os
import numpy as np
import argparse
import re
import subprocess as sp

import desispec.io as io

import desispec.pipeline as pipe


def main():
    parser = argparse.ArgumentParser(description='Set up pipeline runs for a production.')
    parser.add_argument('--raw', required=False, default=None, help='raw data directory')
    parser.add_argument('--redux', required=False, default=None, help='output directory')
    parser.add_argument('--prod', required=False, default='test', help='output production name')
    parser.add_argument('--nights', required=False, default=None, help='comma separated (YYYYMMDD) or regex pattern')
    parser.add_argument('--env', required=False, default=None, help='text file with environment setup commands')
    parser.add_argument('--nerschost', required=False, default='edison', help='machine at NERSC for slurm script generation (edison|cori)')
    parser.add_argument('--fakeboot', required=False, default=None, help='path to input psf-{r,b,z}.fits files, to bypass bootcalib')
    parser.add_argument('--spectrographs', required=False, default=None, help='process only this comma-separated list of spectrographs')

    args = parser.parse_args()

    nodecores = 0
    if args.nerschost == 'edison':
        nodecores = 24
    elif args.nerschost == 'cori':
        nodecores = 32
    else:
        raise RuntimeError("unknown nersc host")

    spectrographs = []
    if args.spectrographs is None:
        for s in range(10):
            spectrographs.append(s)
    else:
        spc = args.spectrographs.split(',')
        for s in spc:
            spectrographs.append(int(s))

    spectrostr = ",".join([ "{}".format(x) for x in spectrographs ])

    frames_per_exp = 3 * len(spectrographs)

    rawdir = args.raw
    if rawdir is None:
        rawdir = io.rawdata_root()
    rawdir = os.path.abspath(rawdir)

    specdir = args.redux
    if specdir is None:
        specdir = io.specprod_root()
    specdir = os.path.abspath(specdir)

    # Create the output directories if needed

    if not os.path.isdir(specdir):
        os.makedirs(specdir)

    proddir = os.path.join(specdir, args.prod)
    if not os.path.isdir(proddir):
        os.makedirs(proddir)
    
    cal2d = os.path.join(proddir, 'calib2d')
    if not os.path.isdir(cal2d):
        os.makedirs(cal2d)

    calpsf = os.path.join(cal2d, 'psf')
    if not os.path.isdir(calpsf):
        os.makedirs(calpsf)

    expdir = os.path.join(proddir, 'exposures')
    if not os.path.isdir(expdir):
        os.makedirs(expdir)

    brkdir = os.path.join(proddir, 'bricks')
    if not os.path.isdir(brkdir):
        os.makedirs(brkdir)

    # Get full list of nights

    print("Selecting nights for processing")

    allnights = []
    nightpat = re.compile(r'\d{8}')
    for root, dirs, files in os.walk(rawdir, topdown=True):
        for d in dirs:
            nightmat = nightpat.match(d)
            if nightmat is not None:
                allnights.append(d)
        break

    # Trim list of nights based on set of patterns

    nights = []
    if args.nights is not None:
        nightsel = args.nights.split(',')
        for sel in nightsel:
            pat = re.compile(sel)
            for nt in allnights:
                mat = pat.match(nt)
                if mat is not None:
                    if nt not in nights:
                        nights.append(nt)
        nights = sorted(nights)
    else:
        nights = sorted(allnights)

    # create per-night directories

    for nt in nights:
        ndir = os.path.join(expdir, nt)
        if not os.path.isdir(ndir):
            os.makedirs(ndir)
        ndir = os.path.join(cal2d, nt)
        if not os.path.isdir(ndir):
            os.makedirs(ndir)
        ndir = os.path.join(calpsf, nt)
        if not os.path.isdir(ndir):
            os.makedirs(ndir)

    # create setup shell snippet

    setupfile = os.path.join(proddir, 'setup.sh')
    with open(setupfile, 'w') as s:
        s.write("# Generated by desi_pipe\n")
        s.write("export DESI_SPECTRO_DATA={}\n".format(rawdir))
        s.write("export DESI_SPECTRO_REDUX={}\n".format(specdir))
        s.write("export PRODNAME={}\n".format(args.prod))
        s.write("\n")

    # load those same things into the environment, so that
    # we can actually execute the planning scripts.

    os.environ['DESI_SPECTRO_DATA'] = rawdir
    os.environ['DESI_SPECTRO_REDUX'] = specdir
    os.environ['PRODNAME'] = args.prod

    # read in the environment setup, if needed

    envcom = []
    if args.env is not None:
        with open(args.env, 'r') as f:
            for line in f:
                envcom.append(line.rstrip())

    # create scripts for processing

    print("Generating nightly scripts")

    scrdir = os.path.join(proddir, 'scripts')
    if not os.path.isdir(scrdir):
        os.makedirs(scrdir)

    logdir = os.path.join(proddir, 'logs')
    if not os.path.isdir(logdir):
        os.makedirs(logdir)

    pixroot = "pix"

    com_master_shell = []
    com_master_nersc = []

    for nt in nights:
        # get the list of exposures and their types
        (expid, exptype, fibermaps, fullraw) = pipe.find_raw(rawdir, nt, spectrographs=spectrographs)

        print("Night {}:".format(nt))

        allarcs = []
        allflats = []
        allscience = []
        for ex in expid:
            if exptype[ex] == "arc":
                allarcs.append(ex)
                print("  {:08d} : arc".format(ex))
            elif exptype[ex] == "flat":
                allflats.append(ex)
                print("  {:08d} : flat".format(ex))
            else:
                allscience.append(ex)
                print("  {:08d} : science".format(ex))

        if len(allarcs) == 0:
            raise RuntimeError("night {} has no calibration exposures".format(nt))
        if len(allflats) == 0:
            raise RuntimeError("night {} has no flats".format(nt))
        if len(allscience) == 0:
            raise RuntimeError("night {} has no science exposures".format(nt))
        
        # make nightly script and log directories
        nsdir = os.path.join(scrdir, nt)
        if not os.path.isdir(nsdir):
            os.makedirs(nsdir)
        nldir = os.path.join(logdir, nt)
        if not os.path.isdir(nldir):
            os.makedirs(nldir)

        # create scripts to run bootcalib
        if args.fakeboot is not None:
            for band in ['b', 'r', 'z']:
                truepsf = os.path.join(args.fakeboot, "psf-{}.fits".format(band))
                for spec in spectrographs:
                    lnk = os.path.join(calpsf, nt, "psfboot-{}{}.fits".format(band, spec))
                    if not os.path.islink(lnk):
                        os.symlink(truepsf, lnk)
        else:
            firstarc = allarcs[0]
            firstflat = allflats[0]
            commands = []
            for cam in sorted(fullraw[firstarc].keys()):
                spc = int(cam[1])
                if spc in spectrographs:
                    flatname = "{}-{}-{:08d}.fits".format(pixroot, cam, firstflat)
                    flatfile = os.path.join(rawdir, nt, flatname)
                    arcname = "{}-{}-{:08d}.fits".format(pixroot, cam, firstarc)
                    arcfile = os.path.join(rawdir, nt, arcname)
                    outname = "psfboot-{}.fits".format(cam)
                    outfile = os.path.join(calpsf, nt, outname)
                    commands.append("desi_bootcalib.py --fiberflat {} --arcfile {} --outfile {}".format(flatfile, arcfile, outfile))
            shell_file = os.path.join(nsdir, "bootcalib.sh")
            nersc_file = os.path.join(nsdir, "bootcalib.nersc")
            shell_log = os.path.join(nldir, "bootcalib_sh")
            nersc_log = os.path.join(nldir, "bootcalib_nersc")
            pipe.shell_job(shell_file, shell_log, envcom, setupfile, commands)
            pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, commands, nodes=1, nodeproc=1, minutes=30, multisrun=True, openmp=False, multiproc=False)

            com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run specex

        lamplines = "/project/projectdirs/desi/software/edison/specex/specex-0.3.4/data/lamplines-specex.par"

        shell_file = os.path.join(nsdir, "specex.sh")
        nersc_file = os.path.join(nsdir, "specex.nersc")
        dump_file = os.path.join(nsdir, "specex_commands.txt")
        shell_log = os.path.join(nldir, "specex_sh")
        nersc_log = os.path.join(nldir, "specex_nersc")

        comopts = "--lamplines {} --night {} --spectrographs {}".format(lamplines, nt, spectrostr)
        
        complan = "desi_plan_psf {} --dump {}".format(comopts, dump_file)
        #spret = sp.call(complan, shell=True)

        com = "desi_pipe_psf {}".format(comopts)

        pipe.shell_job(shell_file, shell_log, envcom, setupfile, [com])

        # we want to use enough nodes to run one exposure simultaneously.
        nbundle = len(allarcs) * frames_per_exp * 20
        nodeproc = 8
        runnodes = int(nbundle / nodeproc)
        if runnodes * nodeproc != nbundle:
            runnodes += 1
        # for one exposure, there are 600 bundles.  If we run 8 per node
        # (which works well for 24 or 32 cores per node), then we want 
        # 75 nodes.  Specex is OpenMP parallel.
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, [com], nodes=runnodes, nodeproc=nodeproc, minutes=30, openmp=True, multiproc=False)

        com_master_shell.append("bash {}".format(shell_file))

        # Create script to generate best psf

        commands = []
        for cam in sorted(fullraw[allarcs[0]].keys()):
            outname = "psf-{}.fits".format(cam)
            outfile = os.path.join(calpsf, nt, outname)
            infiles = []
            for arc in allarcs:
                spc = int(cam[1])
                if spc in spectrographs:
                    psfname = "psf-{}-{:08d}.fits".format(cam, arc)
                    psffile = os.path.join(expdir, nt, "{:08d}".format(arc), psfname)
                    infiles.append(psffile)
            commands.append("specex_mean_psf.py --output {} --input {}".format(outfile, " ".join(infiles)))
        
        shell_file = os.path.join(nsdir, "meanpsf.sh")
        nersc_file = os.path.join(nsdir, "meanpsf.nersc")
        shell_log = os.path.join(nldir, "meanpsf_sh")
        nersc_log = os.path.join(nldir, "meanpsf_nersc")
        pipe.shell_job(shell_file, shell_log, envcom, setupfile, commands)
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, commands, nodes=1, nodeproc=1, minutes=10, multisrun=True, openmp=False, multiproc=False)

        com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run exspec

        shell_file = os.path.join(nsdir, "exspec.sh")
        nersc_file = os.path.join(nsdir, "exspec.nersc")
        dump_file = os.path.join(nsdir, "exspec_commands.txt")
        shell_log = os.path.join(nldir, "exspec_sh")
        nersc_log = os.path.join(nldir, "exspec_nersc")

        comopts = "--night {} --spectrographs {}".format(nt, spectrostr)
        
        complan = "desi_plan_extract {} --dump {}".format(comopts, dump_file)
        #spret = sp.call(complan, shell=True)

        com = "desi_pipe_extract {}".format(comopts)
        
        pipe.shell_job(shell_file, shell_log, envcom, setupfile, [com])
        # we want to run all tasks at once.  we use one core per task.
        nbundle = (len(allscience) + len(allflats)) * frames_per_exp * 20
        nodeproc = 8
        runnodes = int(nbundle / nodeproc)
        if runnodes * nodeproc != nbundle:
            runnodes += 1
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, [com], nodes=runnodes, nodeproc=nodeproc, minutes=30, openmp=False, multiproc=True)

        com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run calibration

        shell_file = os.path.join(nsdir, "calib.sh")
        nersc_file = os.path.join(nsdir, "calib.nersc")
        dump_file = os.path.join(nsdir, "calib_commands.txt")
        shell_log = os.path.join(nldir, "calib_sh")
        nersc_log = os.path.join(nldir, "calib_nersc")

        comopts = "--night {}".format(nt)
        
        complan = "desi_plan_calib {} --dump {}".format(comopts, dump_file)
        #spret = sp.call(complan, shell=True)

        com = "desi_pipe_calib {}".format(comopts)

        pipe.shell_job(shell_file, shell_log, envcom, setupfile, [com])
        # fiberflat is much more expensive than the other steps.
        # so we use the number of flats to set the concurrency.
        nframe = len(allflats) * frames_per_exp
        nodeproc = nodecores
        runnodes = int(nframe / nodeproc)
        if runnodes * nodeproc != nframe:
            runnodes += 1
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, [com], nodes=runnodes, nodeproc=nodeproc, minutes=30, openmp=False, multiproc=True)

        com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run make bricks

        commands = []
        commands.append("desi_make_bricks.py --night {}".format(nt))
        shell_file = os.path.join(nsdir, "bricks.sh")
        nersc_file = os.path.join(nsdir, "bricks.nersc")
        shell_log = os.path.join(nldir, "bricks_sh")
        nersc_log = os.path.join(nldir, "bricks_nersc")
        pipe.shell_job(shell_file, shell_log, envcom, setupfile, commands)
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, commands, nodes=1, nodeproc=1, minutes=30, openmp=False, multiproc=False)

        com_master_shell.append("bash {}".format(shell_file))

        # Create scripts to run zfind

        shell_file = os.path.join(nsdir, "zfind.sh")
        nersc_file = os.path.join(nsdir, "zfind.nersc")
        dump_file = os.path.join(nsdir, "zfind_commands.txt")
        shell_log = os.path.join(nldir, "zfind_sh")
        nersc_log = os.path.join(nldir, "zfind_nersc")
        
        complan = "desi_plan_zfind --dump {}".format(dump_file)
        #spret = sp.call(complan, shell=True)

        com = "desi_pipe_zfind"

        pipe.shell_job(shell_file, shell_log, envcom, setupfile, [com])

        # one process per node for each brick
        nbricks = len(pipe.get_fibermap_bricknames(fibermaps.values()))
        pipe.nersc_job(nersc_file, nersc_log, envcom, setupfile, [com], nodes=nbricks, nodeproc=1, minutes=30, openmp=False, multiproc=True)

        com_master_shell.append("bash {}".format(shell_file))

    # Create master scripts with job dependencies
    shell_master = os.path.join(scrdir, 'run.sh')
    with open(shell_master, 'w') as f:
        for com in com_master_shell:
            f.write("{}\n".format(com))

    shell_nersc = os.path.join(scrdir, 'run.nersc')
    with open(shell_nersc, 'w') as f:
        for com in com_master_nersc:
            f.write("{}\n".format(com))


if __name__ == "__main__":
    main()

