#!/usr/bin/env python
#
# See top-level LICENSE.rst file for Copyright information
#
# -*- coding: utf-8 -*-

"""
Inspect the current state of a pipeline production and retry failed steps.
"""

from __future__ import absolute_import, division, print_function

import sys
import os
import numpy as np
import argparse
import re
import glob

import yaml

import desispec.io as io
import desispec.pipeline as pipe


def newest_completed(rundir, first, last):
    file = ""
    time = 0
    for out in glob.glob(os.path.join(rundir, "outstate_{}-{}_*.yaml".format(first, last))):
        cur = os.path.getmtime(out)
        if cur > time:
            time = cur
            file = out
    return file, time


def check_runcrash(rundir, step):
    started = False
    running = False
    jobpat = re.compile('.*running_{}_(.*)'.format(step))
    slrmpat = re.compile(r'slurm-(.*)')
    runfiles = []
    for run in glob.glob(os.path.join(rundir, "running_{}_*".format(step))):
        runfiles.append(run)
    if len(runfiles) == 0:
        return started, running

    newest = runfiles[0]
    tnewest = os.path.getmtime(newest)
    if len(runfiles) > 1:
        for r in range(1, len(runfiles))
            t = os.path.getmtime(runfiles[r])
            if t > tnewest:
                newest = runfiles[r]
                tnewest = t

    started = True

    jobmat = jobpat.match(newest)
    if jobmat is None:
        raise RuntimeError("running file matches glob but not regex- should never get here!")
    jobid = jobmat.group(1)
    slrmmat = slrmpat.match(jobid)
    if slrmmat is None:
        # we were just using bash...
        pid = int(jobid)
        if pipe.pid_exists(pid):
            running = True
    else:
        slrmid = int(slrmmat.group(1))
        state = sp.check_output("squeue -j {} | tail -1 | gawk '{{print $10}}'".format(slrmid), shell=True)
        if state == 'R':
            running = True

    return started, running


def main():
    parser = argparse.ArgumentParser(description='Explore pipeline status.')
    parser.add_argument('--raw', required=False, default=None, help='raw data directory')
    parser.add_argument('--redux', required=False, default=None, help='output directory')
    parser.add_argument('--prod', required=False, default=None, help='output production name')
    parser.add_argument('--cleanup', required=False, default=None, action="store_true", help='clean up stale files from crashed jobs')
    parser.add_argument('--vis', required=False, default=None, action="store_true", help='use graphviz to display state')
    parser.add_argument('--failed', required=False, default=None, help='info about the failed yaml file')
    parser.add_argument('--retry', required=False, default=None, help='re-try to run the failed yaml file')

    args = parser.parse_args()

    rawdir = args.raw
    if rawdir is None:
        rawdir = io.rawdata_root()
    rawdir = os.path.abspath(rawdir)

    specdir = args.redux
    if specdir is None:
        if 'DESI_SPECTRO_REDUX' not in os.environ:
            raise RuntimeError("You must set DESI_SPECTRO_REDUX in your environment or with a commandline option")
        specdir = os.path.abspath(os.environ['DESI_SPECTRO_REDUX'])

    prodname = args.prod
    if prodname is None:
        if 'PRODNAME' not in os.environ:
            raise RuntimeError("You must set PRODNAME in your environment or with a commandline option")
        prodname = os.environ['PRODNAME']

    proddir = os.path.join(specdir, prodname)

    expdir = os.path.join(proddir, 'exposures')

    rundir = os.path.join(proddir, 'run')

    faildir = os.path.join(run, 'failed')

    cal2d = os.path.join(proddir, 'calib2d')
    calpsf = os.path.join(cal2d, 'psf')

    # are we just working with a single failed task?

    if args.failed is not None:
        fyml = None
        with open(args.failed, 'r') as f:
            fyml = yaml.load(f)

        step = fyml['step']
        rawdir = fyml['rawdir']
        proddir = fyml['proddir']
        name = fyml['task']
        grph = fyml['graph']
        opts = fyml['opts']
        nproc = fyml['procs']

        print("{} :".format(args.failed))
        print("    step = {}".format(step))
        print("    processes = {}".format(nproc))
        print("    rawdir = {}".format(step))
        print("    proddir = {}".format(step))
        print("    object = {}".format(name))
        print("    opts:")
        for op in opts:
            print("      {}".format(op))
        print("    deps:")
        print(grph)
        print("")

    elif args.retry is not None:
        pipe.retry_task(args.retry)

    else:
        status = {}
        steps = []

        steps.append('bootcalib')

        file, time = newest_completed(rundir, 'bootcalib', 'bootcalib')

        if file == "":
            # did we fake it?
            nightpat = re.compile(r'([0-9]{8})')
            for root, dirs, files in os.walk(calpsf, topdown=True):
                for d in dirs:
                    nightmat = nightpat.match(d)
                    if nightmat is not None:
                        night = nightmat.group(1)
                        lnk = os.path.join(calpsf, night, 'psfboot-r0.fits')
                        if os.path.islink(lnk):
                            status['bootcalib'] = 'done'
                break
        else:
            # are we running now?
            started, running = check_runcrash(rundir, 'bootcalib')



        previous_time = 0

        steps.append('zfind')
        file, time = newest_completed(rundir, 'zfind', 'zfind')


        for s in steps:

    steps = [
        ('bootcalib', 'bootcalib'),
        ('specex', 'specex'),
        ('psfcombine', 'psfcombine'),
        ('extract', 'extract'),
        ('fiberflat', 'procexp'),
        ('bricks', 'bricks'),
        ('zfind', 'zfind')
    ]



    # dot -Tpdf -O <blah.dot>


    



if __name__ == "__main__":
    main()

