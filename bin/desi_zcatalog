#!/usr/bin/env python

"""
Combine individual redrock files into a single zcatalog

NOTE: this could get factored out into script vs. algorithm vs. I/O, but
that would obfuscate the current short simplicity of this script.  Do that
refactor if we find that we have to generate zcatalog data outside of the
context of this script.

Stephen Bailey
Lawrence Berkeley National Lab
Fall 2015
"""

from __future__ import absolute_import, division, print_function

import sys, os, glob
import argparse

import numpy as np
from numpy.lib.recfunctions import append_fields

import fitsio
from astropy.table import Table, hstack, vstack

from desiutil.log import get_logger
from desispec import io
from desispec.zcatalog import find_primary_spectra
from desispec.io.util import get_tempfilename

def match(table1,table2,key="TARGETID") :
    """
    matching two tables
    
    Args:
        table1 : a numpy recarray
        table2 : another numpy recarray
        key : string, the key of the columns to match
    
    Returns joined table
    """
    
    log=get_logger()
    k1=table1[key]
    k2=table2[key]
    log.debug(f'Mapping {key} between tables')
    d2  =  {v : i for i,v in enumerate(k2)}
    i21 = np.array([d2.get(v,-1) for v in k1]) # not always a match
    ok=(i21>=0)

    #- lists of columns to add
    colnames = list()
    coldata = list()

    log.debug('Identifying columns to add')
    for k in table2.dtype.names :
        if k in table1.dtype.names :
            log.debug(f'Skipping {k} already in table1')
            continue # do not duplicate columns

        #- Special cases of known 2D columns that will fail append_fields
        if k == 'DCHISQ':
            log.warning('Dropping 2D column {}'.format(k))
            continue

        # log.debug(f'Appending {k} to table1')
        colnames.append(k)
        coldata.append(np.zeros(k1.size, dtype=table2[k].dtype))

    numnewcol = len(colnames)
    numrows1 = len(table1)
    log.debug(f"Adding {numnewcol} columns x {numrows1} rows to table1")
    table1=append_fields(table1, colnames, coldata)

    log.debug('Filling in data from table2')
    for k in colnames:
        table1[k][ok]=table2[k][i21[ok]] # unmatched values are set the 0 value corresponding to the dtype

    log.debug(f'Done with matching tables on {key}')
    return table1

def load_sv1_ivar_w12(hpix, targetids):
    """
    Load FLUX_IVAR_W1/W2 from sv1 target files for requested targetids

    Args:
        hpix (int): nside=8 nested healpix
        targetids (array): TARGETIDs to include

    Returns table of TARGETID, FLUX_IVAR_W1, FLUX_IVAR_W2

    Note: this is only for the special case of sv1 dark/bright and the
    FLUX_IVAR_W1/W2 columns which were not included in fiberassign for
    tiles designed before 20201212.

    Note: nside=8 nested healpix is hardcodes for simplicity because that is
    what was used for sv1 target selection and this is not trying to be a
    more generic targetid lookup function.
    """
    log = get_logger()
    #- the targets could come from any version of desitarget, so search all,
    #- but once a TARGETID is found it will be the same answer (for FLUX_IVAR*)
    #- as any other version because it is propagated from the same dr9 input
    #- Tractor files.
    targetdir = os.path.join(os.environ['DESI_TARGET'], 'catalogs', 'dr9')
    fileglob = f'{targetdir}/*/targets/sv1/resolve/*/sv1targets-*-hp-{hpix}.fits'
    sv1targetfiles = sorted(glob.glob(fileglob))
    nfiles = len(sv1targetfiles)
    ntarg = len(np.unique(targetids))
    log.info(f'Searching {nfiles} sv1 target files for {ntarg} targets in nside=8 healpix={hpix}')
    columns = ['TARGETID', 'FLUX_IVAR_W1', 'FLUX_IVAR_W2']
    targets = list()
    found_targetids = list()
    for filename in sv1targetfiles:
        tx = fitsio.read(filename, 1, columns=columns)
        keep = np.isin(tx['TARGETID'], targetids)
        keep &= ~np.isin(tx['TARGETID'], found_targetids)
        targets.append(tx[keep])
        found_targetids.extend(tx['TARGETID'][keep])

        if np.all(np.isin(targetids, found_targetids)):
            break

    targets = np.hstack(targets)

    missing = np.isin(targetids, targets['TARGETID'], invert=True)
    if np.any(missing):
        nmissing = np.sum(missing)
        log.error(f'{nmissing} TARGETIDs not found in sv1 healpix={hpix}')

    return targets


#--------------------------------------------------------------------------

parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument("-i", "--indir",  type=str,
        help="input directory")
parser.add_argument("-o", "--outfile",type=str,
        help="output file")
parser.add_argument("--minimal", action='store_true',
        help="only include minimal output columns")
parser.add_argument("-t", "--tiles", type=str,
        help="ascii file with tileids to include (one per line)")
parser.add_argument("--prefix", type=str, default='redrock',
        help="prefix of redrock files (older versions used 'zbest' "
             "instead of 'redrock'")
parser.add_argument("-g", "--group", type=str,
        help="Add columns specific to this spectral grouping "
             "e.g. pernight adds NIGHT column from input header keyword")
parser.add_argument("--header", type=str, nargs="*",
        help="KEYWORD=VALUE entries to add to the output header")
parser.add_argument('--patch-missing-ivar-w12', action='store_true',
        help="Use target files to patch missing FLUX_IVAR_W1/W2 values")

# parser.add_argument("--match", type=str, nargs="*",
#         help="match other tables (targets,truth...)")

args = parser.parse_args()

log=get_logger()

if args.indir is None:
    log.error('--indir directory required')
    sys.exit(1)
    
if args.outfile is None:
    args.outfile = io.findfile('zcatalog')

#- Get redrock*.fits files in subdirs, excluding e.g. redrock*.log

log.info(f'Looking for redrock files in subdirectories of {args.indir}')
if args.tiles is not None:
    tiles = np.atleast_1d(np.loadtxt(args.tiles, dtype=int))
    ntiles = len(tiles)
    log.info(f'Filtering to {ntiles} tiles from {args.tiles}')
    redrockfiles = list()
    for tileid in tiles:
        tmp = sorted(io.iterfiles(f'{args.indir}/{tileid}', prefix=args.prefix, suffix='.fits'))
        if len(tmp) > 0:
            redrockfiles.extend(tmp)
        else:
            log.error(f'no redrock files found in {args.indir}/{tileid}')
else:
    redrockfiles = sorted(io.iterfiles(args.indir, prefix=args.prefix, suffix='.fits'))

nfiles = len(redrockfiles)
if nfiles == 0:
    msg = f'No redrock files found in {args.indir}'
    log.critical(msg)
    raise ValueError(msg)

zcatdata = list()
exp_fibermaps = list()
for ifile, rrfile in enumerate(redrockfiles):
    log.info(f'Reading {ifile+1}/{nfiles} {rrfile}')
    with fitsio.FITS(rrfile) as fx:
        hdr = fx[0].read_header()
        if args.group is not None and 'SPGRP' in hdr and \
                hdr['SPGRP'] != args.group:
            log.warning("Skipping {} with SPGRP {} != args.group {}".format(
                rrfile, hdr['SPGRP'], args.group))
            continue

        if 'ZBEST' in fx: #check if the older hdu name for REDSHIFT exist, in which case we read only the FIBERMAP and no TSNR2.
            redshifts = fx['ZBEST'].read()
            fibermap = fx['FIBERMAP'].read()
            assert np.all(redshifts['TARGETID'] == fibermap['TARGETID'])
            if ['EXP_FIBERMAP','TSNR2'] in fx:
                expfibermap = fx['EXP_FIBERMAP'].read()
                tsnr2 = fx['TSNR2'].read()
                assert np.all(redshifts['TARGETID'] == tsnr2['TARGETID'])
            else:
                expfibermap = None
                tsnr2 = None

        else:
            redshifts = fx['REDSHIFTS'].read()
            fibermap = fx['FIBERMAP'].read()
            expfibermap = fx['EXP_FIBERMAP'].read()
            tsnr2 = fx['TSNR2'].read()
            assert np.all(redshifts['TARGETID'] == fibermap['TARGETID'])
            assert np.all(redshifts['TARGETID'] == tsnr2['TARGETID'])

    if args.minimal:
        fmcols = ['TARGET_RA', 'TARGET_DEC', 'FLUX_G', 'FLUX_R', 'FLUX_Z']
        for colname in fibermap.dtype.names:
            if colname.endswith('_TARGET') and colname != 'FA_TARGET':
                fmcols.append(colname)
        if args.prefix == 'zbest':
            fibermap_=Table(fibermap[fmcols])
            fibermap_.rename_column('TARGET_RA','RA')
            fibermap_.rename_column('TARGET_DEC','DEC')
            fibermap_.remove_columns(['DESI_TARGET','BGS_TARGET','MWS_TARGET','SCND_TARGET'])
            data = hstack( [Table(redshifts), fibermap_] )

        else:
            data = hstack( [Table(redshifts), Table(fibermap[fmcols])] )

    else:
        fmcols = list(fibermap.dtype.names)
        fmcols.remove('TARGETID')
        if tsnr2 is not None:
            tsnr2cols = list(tsnr2.dtype.names)
            tsnr2cols.remove('TARGETID')
            data = hstack([
                Table(redshifts),
                Table(fibermap[fmcols]),
                Table(tsnr2[tsnr2cols]),
                ])
        else:
            data = hstack( [Table(redshifts), Table(fibermap[fmcols])] )

    #- Add group specific columns, recognizing some some of them may
    #- have already been inherited from the fibermap.
    #- Put these columns right after TARGETID
    nrows = len(data)
    icol = 1
    if args.group in ('perexp', 'pernight', 'cumulative'):
        if 'TILEID' not in data.colnames:
            data.add_column(np.full(nrows, hdr['TILEID'], dtype=np.int32),
                    index=icol, name='TILEID')
            icol += 1
        if 'PETAL_LOC' not in data.colnames:
            data.add_column(np.full(nrows, hdr['PETAL'], dtype=np.int16),
                    index=icol, name='PETAL_LOC')
            icol += 1

    if args.group == 'perexp':
        data.add_column(np.full(nrows, hdr['NIGHT'], dtype=np.int32),
                index=icol, name='NIGHT')
        icol += 1
        data.add_column(np.full(nrows, hdr['EXPID'], dtype=np.int32),
                index=icol, name='EXPID')
    elif args.group == 'pernight':
        data.add_column(np.full(nrows, hdr['NIGHT'], dtype=np.int32),
                index=icol, name='NIGHT')
    elif args.group == 'cumulative':
        data.add_column(np.full(nrows, hdr['NIGHT'], dtype=np.int32),
                index=icol, name='LASTNIGHT')
    elif args.group == 'healpix':
        data.add_column(np.full(nrows, hdr['HPXPIXEL'], dtype=np.int32),
                index=icol, name='HEALPIX')

    icol += 1

    # SPGRPVAL = night for pernight, expid for perexp, subset for custom coadds
    if 'SPGRPVAL' in hdr.keys():
        val = hdr['SPGRPVAL']
        # if int, try to make int32, otherwise let numpy pick dtype
        if isinstance(val, int):
            if np.int32(val) == val:
                dtype = np.int32
            else:
                dtype = np.int64
        else:
            dtype = None

        data.add_column(np.full(nrows, hdr['SPGRPVAL'], dtype=dtype),
                index=icol, name='SPGRPVAL')
    else:
        log.warning(f'SPGRPVAL keyword missing from {rrfile}')

    zcatdata.append(data)

    if expfibermap is not None:
        exp_fibermaps.append(expfibermap)


log.info('Stacking zcat')
zcat = vstack(zcatdata)
if exp_fibermaps:
    log.info('Stacking exposure fibermaps')
    expfm = np.hstack(exp_fibermaps)
else:
    expfm = None

#- if TARGETIDs appear more than once, which one is best within this catalog?
if 'TSNR2_LRG' in zcat.colnames and 'ZWARN' in zcat.colnames:
    log.info('Finding best spectrum for each target')
    nspec, primary = find_primary_spectra(zcat)
    zcat['ZCAT_NSPEC'] = nspec.astype(np.int16)
    zcat['ZCAT_PRIMARY'] = primary
else:
    log.info('Missing TSNR2_LRG or ZWARN; not adding ZCAT_PRIMARY/_NSPEC')

if args.patch_missing_ivar_w12:
    from desimodel.footprint import radec2pix
    missing = (zcat['FLUX_IVAR_W1'] < 0) | (zcat['FLUX_IVAR_W2'] < 0)
    missing &= zcat['OBJTYPE'] == 'TGT'
    missing &= zcat['TARGETID'] > 0

    if not np.any(missing):
        log.info('No targets missing FLUX_IVAR_W1/W2 to patch')
    else:
        #- Load targets from sv1 targeting files
        ra = zcat['TARGET_RA']
        dec = zcat['TARGET_DEC']
        nside = 8  #- use for sv1 targeting
        hpix8 = radec2pix(nside, ra, dec)
        for hpix in np.unique(hpix8[missing]):
            hpixmiss = (hpix == hpix8) & missing
            targets = load_sv1_ivar_w12(hpix, zcat['TARGETID'][hpixmiss])

            #- create dict[TARGETID] -> row number
            targetid2idx = dict(zip(targets['TARGETID'],
                                    np.arange(len(targets))))

            #- patch missing values, if they are in the targets file
            for i in np.where(hpixmiss)[0]:
                tid = zcat['TARGETID'][i]
                try:
                    j = targetid2idx[ tid ]
                    zcat['FLUX_IVAR_W1'][i] = targets['FLUX_IVAR_W1'][j]
                    zcat['FLUX_IVAR_W2'][i] = targets['FLUX_IVAR_W2'][j]
                except KeyError:
                    log.warning(f'TARGETID {tid} (row {i}) not found in sv1 targets')

#- we're done adding columns, convert to numpy array for fitsio
zcat = np.array(zcat)

#- untested with new formats, so commenting out for now
# if args.match:
#     for filename in args.match :
#         log.info("matching {}".format(filename))
#         zcat = match(zcat,fitsio.read(filename))

#- Inherit header from first input, but remove keywords that don't apply
#- across multiple files
header = fitsio.read_header(redrockfiles[0], 0)
for key in ['SPGRPVAL', 'TILEID', 'SPECTRO', 'PETAL', 'NIGHT', 'EXPID', 'HPXPIXEL']:
    if key in header:
        header.delete(key)

if args.header is not None:
    for keyval in args.header:
        key, value = keyval.split('=', maxsplit=1)
        try:
            header[key] = int(value)
        except ValueError:
            header[key] = value

log.info(f'Writing {args.outfile}')
tmpfile = get_tempfilename(args.outfile)
fitsio.write(tmpfile, zcat, header=header, extname='ZCATALOG', clobber=True)

if not args.minimal and expfm is not None:
    fitsio.write(tmpfile, expfm, extname='EXP_FIBERMAP')

os.rename(tmpfile, args.outfile)

log.info("Successfully wrote {}".format(args.outfile))

