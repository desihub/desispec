#!/usr/bin/env python
'''
Calculate stand alone tsnr tables for a given desispec prod.

Use MPI:
    salloc -N 2 -C haswell -q interactive -t 00:30:00

    # 2 nodes, 2 mpi ranks reducing 2 nights (1 per rank) with 32 processes.
    srun -N 2 -n 2 -c 32 python desi_tsnr_afterburner
'''

import os,sys
import json
import glob
import itertools
import argparse
import astropy.io.fits as fits
import fitsio
import numpy as np
import multiprocessing
from astropy.table import Table,vstack

import yaml
from   pkg_resources import resource_filename

from   desispec.io import read_sky
from   desispec.io import read_fiberflat
from   pathlib import Path
from   desispec.io.meta import findfile, specprod_root
from   desispec.calibfinder import CalibFinder
from   desispec.io import read_frame
from   desispec.io import read_fibermap
from   desispec.io.fluxcalibration import read_flux_calibration
from   desiutil.log import get_logger
from   desispec.tsnr import calc_tsnr2,tsnr2_to_efftime
from   astropy.table import Table, vstack
from   desiutil.depend import getdep
from   desispec.tilecompleteness import compute_tile_completeness_table,merge_tile_completeness_table
from   desispec.skymag import compute_skymag
from   desispec.efftime import compute_efftime
from   desispec.parallel import  stdouterr_redirected, use_mpi
from   desispec.util import parse_int_args


def parse(options=None):
    parser = argparse.ArgumentParser(
                description="Calculate template S/N ratio for exposures")
    parser.add_argument('-o','--outfile', type=str, default=None, required=False,
                        help = 'Output summary file')
    parser.add_argument('--update', action = 'store_true',
                        help = 'Update pre-existing output summary file (replace or append)')
    parser.add_argument('--details-dir', type=str, default = None, required=False,
                        help = 'Dir. to write per-exposure per-camera files with per-fiber tSNR details')
    parser.add_argument('--prod', type = str, default = None, required=False,
                        help = 'Path to input reduction, e.g. /global/cfs/cdirs/desi/spectro/redux/blanc/,  or simply prod version, like blanc, but requires env. variable DESI_SPECTRO_REDUX. Default is $DESI_SPECTRO_REDUX/$SPECPROD.')
    parser.add_argument('--cameras', type = str, default = None, required=False,
                        help = 'Cameras to reduce (comma separated)')
    parser.add_argument('--expids', type = str, default = None, required=False,
                        help = 'Comma separated list of exp ids to process')
    parser.add_argument('--nights', type = str, default = None, required=False,
                        help = 'Comma, or colon separated list of nights to process. ex: 20210501,20210502 or 20210501:20210531')
    parser.add_argument('--recompute', action='store_true',
                        help = 'Recompute TSNR values')
    parser.add_argument('--alpha_only', action='store_true',
                        help = 'Only compute the alpha for tsnr.')
    parser.add_argument('--nproc', type = int, default = 1,
                        help = 'Multiprocessing.')
    parser.add_argument('--efftime-config', type = str, default = None, required=False,
                        help = 'Use this config file instead of default data/tsnr/tsnr-efftime.yaml')
    parser.add_argument('--tile-completeness', type = str, default = None, required=False,
                        help = 'Output tile completeness table')
    parser.add_argument('--aux', type = str, default = None, required=False, nargs="*",
                        help = 'Path to auxiliary tiles tables, like /global/cfs/cdirs/desi/survey/observations/SV1/sv1-tiles.fits (optional, will not affect exposures after SV1)')
    parser.add_argument('--gfa-proc-dir', type = str, default = None, required=False,
                        help = 'Directory where the GFA processing from Aaron can be found, like /global/cfs/cdirs/desi/survey/GFA/')
    parser.add_argument('--skymags', type = str, default = None, required=False,
                        help = 'path to table with sky magnitudes. Expected keys=NIGHT,EXPID,SKY_MAG_G,SKY_MAG_R,SKY_MAG_Z')
    parser.add_argument('--compute-skymags', action='store_true',
                        help = 'recompute sky mags')
    parser.add_argument('--multinode', action='store_true',
                        help = 'Paralleize TSNR recomputation across multiple nodes using mpi4py. Requires args.update to be False.')

    args = None
    if options is None:
        args = parser.parse_args()
    else:
        args = parser.parse_args(options)
    return args


def get_targ_info(targ_in):
    """
    Returns information from targeting.

    Args:
        targ_in: dictionary with a single value per key (either built from header
                    or from a Table).

    Returns:
        targ_out: dictionary with SURVEY, GOALTYPE, FAPRGRM, FAFLAVOR, MINTFRAC, GOALTIME.
    """
    targ_keys = list(targ_in.keys())
    targ_out = {
        "SURVEY" : "unknown",
        "GOALTYPE" : "unknown",
        "FAPRGRM" : "unknown",
        "FAFLAVOR" : "unknown",
        "MINTFRAC" : 0.9,
        "GOALTIME" : 0.,
    }
    #
    for k in ["SURVEY","GOALTYPE","FAPRGRM","FAFLAVOR"] :
        if k in targ_keys :
            targ_out[k] = targ_in[k].strip().lower()
    for k in ["MINTFRAC", "GOALTIME"]:
        if k in targ_keys :
            targ_out[k] = targ_in[k]
    #
    if "FAFLAVOR" in targ_keys :
        faflavor=targ_in["FAFLAVOR"].strip().lower()
        #
        if targ_out["FAPRGRM"] == "unknown"  :
            targ_out["FAPRGRM"] = faflavor.replace("sv1","").replace("sv2","").replace("cmx","")
        #
        if targ_out["SURVEY"]=="unknown" :
            if faflavor.find("sv1")>=0. : targ_out["SURVEY"]="sv1"
            elif faflavor.find("sv2")>=0. : targ_out["SURVEY"]="sv2"
            elif faflavor.find("cmx")>=0. : targ_out["SURVEY"]="cmx"
        #
    if targ_out["GOALTYPE"]=="unknown" :
        if targ_out["FAPRGRM"].find("qso")>=0. or targ_out["FAPRGRM"].find("lrg")>=0.  or targ_out["FAPRGRM"].find("elg")>=0. or targ_out["FAPRGRM"].find("dark")>=0. :
            targ_out["GOALTYPE"]="dark"
        elif targ_out["FAPRGRM"].find("mws")>=0. or targ_out["FAPRGRM"].find("bgs")>=0. or targ_out["FAPRGRM"].find("bright")>=0. :
            targ_out["GOALTYPE"]="bright"
    #
    return targ_out


def read_gfa_data(gfa_proc_dir) :
    """
    Read the directory with the offline GFA data reduction (like /global/cfs/cdirs/desi/survey/GFA/),
    find the latest version of the table files for the various surveys, return the merged table.
    See documentation here https://desi.lbl.gov/trac/wiki/SurveyValidation/SV1/conditions/summary_files
    Args:
      gfa_proc_dir: str, directory path
    returns astropy.table.Table
    """
    log = get_logger()
    tables=[]
    for survey in ["SV1","SV2","SV3"] :
        filenames=sorted(glob.glob("{}/offline_matched_coadd_ccds_{}-thru_????????.fits".format(gfa_proc_dir,survey)))
        if len(filenames)==0 : continue
        filename=filenames[-1]
        log.info(f"Reading {filename}")
        table=Table.read(filename,2)# HDU2 is average over frames during spectro exposure and median across CCDs
        tables.append(table)
    if len(tables)==0 :
        log=get_logger()
        mess="did not find any file offline_matched_coadd_ccds_*-thru_????????.fits in {}".format(gfa_proc_dir)
        log.critical(mess)
        raise RuntimeError(mess)
    table=vstack(tables)
    log.info(f'{len(table)} GFA table entries')
    return table



def compute_tsnr_values(cframe_filename,cframe_hdulist,night,expid,camera,specprod_dir, alpha_only=False) :
    """
    Computes TSNR values
    Args:
       cframe_filename: str, cframe file path
       cframe_hdulist: astropy.fits.HDUlist object
       night: int
       expid: int
       camera: str
       specprod_dir: str, production directory
       alpha_only: bool, set to True to only recompute alpha

    Returns: astropy.table.Table obkect with TSNR values
    """
    log = get_logger()

    calib  = findfile('fluxcalib', night=night, expid=expid,
                      camera=camera, specprod_dir=specprod_dir)

    hdr0 = cframe_hdulist[0].header
    hdr1 = cframe_hdulist[1].header

    if 'FIBERFLT' not in hdr0:
        log.critical('Failed to find FIBERFLT in cframe hdr of {:08d} on {}'.format(expid, night))
        log.info('Trying CalibFinder.')

        flat = CalibFinder([hdr0, hdr1]).findfile('FIBERFLAT')

    else:
        flat = cframe_hdulist[0].header['FIBERFLT']

    if 'SPECPROD' in flat:
        flat = flat.replace('SPECPROD', specprod_dir)
    if 'SPCALIB' in flat:
        hdr  = fitsio.read_header(cframe_filename)
        flat = flat.replace('SPCALIB', getdep(hdr, 'DESI_SPECTRO_CALIB'))

    if os.path.exists(flat):
        log.info('Retrieved {}'.format(flat))
    else:
        raise ValueError('Failed on flat retrieval for {} on {}.'.format(expid, night))

    iin = cframe_filename.replace('cframe', 'frame')
    sky = cframe_filename.replace('cframe', 'sky')
    psf = cframe_filename.replace('cframe', 'psf')

    frame=read_frame(iin, skip_resolution=True)
    fiberflat=read_fiberflat(flat)
    fluxcalib=read_flux_calibration(calib)
    skymodel=read_sky(sky)

    results, alpha = calc_tsnr2(frame, fiberflat=fiberflat,
                                skymodel=skymodel, fluxcalib=fluxcalib, alpha_only=alpha_only)

    table=Table()
    for k in results:
        table[k] = results[k].astype(np.float32)
    table["TSNR2_ALPHA_"+camera[0].upper()] = np.repeat(alpha,len(frame.flux))

    return table


def update_table(table1,table2,keys) :
    """ Replace or append rows of table1 with content of table2 indexed by keys

    Args:
        table1: astropy.table.Table
        table2: astropy.table.Table
        keys: list of str

    Returns astropy.table.Table
    """

    log = get_logger()

    v1=table1[keys[0]]
    v2=table2[keys[0]]
    if len(keys)>1 : # I don't know how of a better generic way to create a joined index
        v1=v1.astype("str")
        v2=v2.astype("str")
        for k in keys[1:] :
            v1=[i+j for i,j in zip(v1,table1[k].astype(str))]
            v2=[i+j for i,j in zip(v2,table2[k].astype(str))]

    replace = np.in1d(v1,v2)
    keep = ~replace

    log.info("keep {} entries, replace {}, add {}".format(np.sum(keep),np.sum(replace),len(table2)-np.sum(replace)))

    if np.sum(keep)>0 :
        for k in table2.dtype.names :
            if k not in table1.dtype.names :
                log.info("add new column {}".format(k))
                table1[k]=np.zeros(len(table1),dtype=table2[k].dtype)
        return vstack([table1[keep],table2])
    else :
        return table2

def compute_summary_tables(summary_rows,efftime_config,preexisting_tsnr2_expid_table,preexisting_tsnr2_frame_table,specprod_dir, add_missing=True) :
    """ Compute summary tables.

    Args:
      summary_rows: list of dictionnaries
      output_filename: str, output filename
      efftime_config: dictionnary with scaling factors from TSNR2 to effective exp. time
      preexisting_tsnr2_expid_table: None or astropy.table.Table, update this table if not None
      preexisting_tsnr2_frame_table: None or astropy.table.Table, update this table if not None
      specprod_dir: str, production directory

    Returns tsnr2_expid_table , tsnr2_frame_table
    """
    log = get_logger()

    #- Create camera summary table; specify names to preserve column order
    colnames = list(summary_rows[0].keys())
    for row in summary_rows :
        if len(row.keys()) != len(colnames) :
            log.error("colnames={} but row={}".format(colnames,row))
            sys.exit(12)

    cam_summary = Table(rows=summary_rows, names=colnames)
    cam_summary.meta['EXTNAME'] = 'TSNR2_FRAME'

    tsnr2_colnames = [x for x in cam_summary.colnames if x.startswith('TSNR2_')]

    #- which rows go with which petals:
    ispetal = dict()
    for petal in range(10):
        ii  = (cam_summary['CAMERA'] == 'b'+str(petal))
        ii |= (cam_summary['CAMERA'] == 'r'+str(petal))
        ii |= (cam_summary['CAMERA'] == 'z'+str(petal))
        ispetal[petal] = ii

    #- Distill into exposure summary per-petal
    rows = list()

    #- The unique key is the exposure Id
    for expid in np.unique(cam_summary['EXPID'] ) :
        ii = (cam_summary['EXPID'] == expid)

        row = dict()
        for k in ["NIGHT","EXPID","TILEID","AIRMASS","EBV","SEEING_ETC","EFFTIME_ETC","SURVEY","GOALTYPE","MINTFRAC","FAPRGRM","FAFLAVOR","GOALTIME"] :
            row[k]=cam_summary[k][ii][0]
        # mean
        row["EXPTIME"]=float(np.mean(cam_summary['EXPTIME'][ii]))

        #- Per EXPID TSNR2 is summed over cameras, averaged over petals
        for colname in tsnr2_colnames:
            tsnr2_petal = list()  #- TSNR^2 summed over cameras, per petal
            for petal in range(10):
                jj = ii & ispetal[petal]
                if np.any(jj):
                    tsnr2_petal.append(np.sum(cam_summary[colname][jj]))
            row[colname] = np.mean(tsnr2_petal) # mean of petals (each being median of valid fibers)

        rows.append(row)

    colnames = list(rows[0].keys())
    exp_summary = Table(rows=rows, names=colnames)
    exp_summary.meta['EXTNAME'] = 'TSNR2_EXPID'

    if add_missing:
      # check the production exposure table
      for night in np.unique(exp_summary["NIGHT"]) :
        prod_table_filename = os.path.join(specprod_dir,"exposure_tables/{}/exposure_table_{}.csv".format(night//100,night))
        if not os.path.isfile(prod_table_filename) :
            log.warning("cannot find prod. exposure table {}".format(prod_table_filename))
            continue
        prod_table = Table.read(prod_table_filename)
        missing = (~(np.in1d(prod_table["EXPID"],exp_summary["EXPID"])))&(prod_table["TILEID"]>0)
        nmissing=np.sum(missing)
        if nmissing>0 :

            ucam=np.unique(cam_summary["CAMERA"])

            for i in np.where(missing)[0] :
                entry={}
                entry["EXPID"]=prod_table["EXPID"][i]
                entry["NIGHT"]=night
                entry["TILEID"]=prod_table["TILEID"][i]
                entry["AIRMASS"]=0.
                entry["EBV"]=0.
                # EBVFAC from https://github.com/desihub/fiberassign/blob/466a99b926892be60c3c9679f521785e865ce315/py/fiberassign/fba_launch_io.py#L1658
                if "EBVFAC" in prod_table.dtype.names:
                    entry["EBV"] = 2.5 * np.log10(prod_table["EBVFAC"][i]) / 2.165
                entry["EXPTIME"]=prod_table["EXPTIME"][i]
                entry['SEEING_ETC']=0.
                entry['EFFTIME_ETC']=0.

                # SURVEY, GOALTYPE, FAPRGRM, FAFLAVOR, MINTFRAC, GOALTIME
                targ_dict = {key : prod_table[key][i] for key in prod_table.dtype.names}
                targ_out = get_targ_info(targ_dict)
                for k in list(targ_out.keys()):
                    entry[k] = targ_out[k]

                vals=[]
                for j,k in enumerate(exp_summary.dtype.names) :
                    if k in entry :
                        vals.append(entry[k])
                    else :
                        vals.append(0.)
                log.warning("Adding missing exposure {}".format(vals))
                exp_summary.add_row(vals)

                # same for other table
                for cam in ucam :
                    entry["CAMERA"]=cam
                    vals=[]
                    for j,k in enumerate(cam_summary.dtype.names) :
                        if k in entry :
                            vals.append(entry[k])
                        else :
                            vals.append(0.)
                    log.debug("Adding missing exposure.cam {}".format(vals))
                    cam_summary.add_row(vals)


    if preexisting_tsnr2_expid_table is not None :
        log.debug("Update to preexisting")

        # backward compatibility issue
        for k in ["SURVEY","GOALTYPE","FAPRGRM","FAFLAVOR"] :
            nentries=len(preexisting_tsnr2_expid_table)
            if k not in preexisting_tsnr2_expid_table.dtype.names :
                log.warning("adding column {}".format(k))
                preexisting_tsnr2_expid_table[k] = np.array(np.repeat("unknown",nentries),dtype='<U16')
        for k in ["GOALTIME","MINTFRAC","SEEING_ETC","EFFTIME_ETC","AIRMASS","EBV"]:
            if k not in preexisting_tsnr2_expid_table.dtype.names :
                log.warning("adding column {}".format(k))
                preexisting_tsnr2_expid_table[k] = np.array(np.repeat(0.,nentries),dtype=float)

        exp_summary = update_table(preexisting_tsnr2_expid_table,exp_summary,["EXPID"])
    if preexisting_tsnr2_frame_table is not None :
        log.debug("Update to preexisting")
        cam_summary = update_table(preexisting_tsnr2_frame_table,cam_summary,["EXPID","CAMERA"])

    log.info("Add effective times from TSNR2 values")

    exp_summary['ELG_EFFTIME_DARK']   = tsnr2_to_efftime(exp_summary['TSNR2_ELG'],"ELG")
    exp_summary['BGS_EFFTIME_BRIGHT'] = tsnr2_to_efftime(exp_summary['TSNR2_BGS'],"BGS")

    if 'TSNR2_GPBDARK' in exp_summary.colnames :
        exp_summary['GPB_EFFTIME_DARK']   = tsnr2_to_efftime(exp_summary['TSNR2_GPBDARK'],"GPBDARK")
        exp_summary['GPB_EFFTIME_BRIGHT'] = tsnr2_to_efftime(exp_summary['TSNR2_GPBBRIGHT'],"GPBBRIGHT")
        exp_summary['GPB_EFFTIME_BACKUP'] = tsnr2_to_efftime(exp_summary['TSNR2_GPBBACKUP'],"GPBBACKUP")

    if 'TSNR2_LYA' in exp_summary.colnames :
        exp_summary['LYA_EFFTIME_DARK'] = tsnr2_to_efftime(exp_summary['TSNR2_LYA'],"LYA")

    # EFFTIME SPEC FOR GOALTYPE dark determined by TSNR2_ELG.
    exp_summary['EFFTIME_SPEC'] = exp_summary['ELG_EFFTIME_DARK']

    # EFFTIME SPEC FOR GOALTYPE bright determined by TSNR2_BGS.
    ii = (exp_summary['GOALTYPE']=='bright')
    exp_summary['EFFTIME_SPEC'][ii] = exp_summary['BGS_EFFTIME_BRIGHT'][ii]

    # EFFTIME SPEC FOR GOALTYPE backup determined by TSNR2_GPBBACKUP.
    ii = (exp_summary['GOALTYPE']=='backup')
    exp_summary['EFFTIME_SPEC'][ii] = exp_summary['GPB_EFFTIME_BACKUP'][ii]

    # sort table rows
    ii = np.argsort(exp_summary['EXPID'])
    exp_summary = exp_summary[ii]
    vals=["{}-{}".format(e,c) for e,c in zip(cam_summary['EXPID'],cam_summary['CAMERA'])]
    ii = np.argsort(vals)
    cam_summary = cam_summary[ii]

    if 'TSNR2_ALPHA' in exp_summary.dtype.names : exp_summary.remove_column('TSNR2_ALPHA')

    # sort table columns
    neworder=['NIGHT','EXPID','TILEID','SURVEY','FAPRGRM','FAFLAVOR','EXPTIME','EFFTIME_SPEC','GOALTIME','GOALTYPE','MINTFRAC','AIRMASS','EBV','SEEING_ETC','EFFTIME_ETC','TSNR2_ELG','TSNR2_QSO','TSNR2_LRG','TSNR2_LYA','TSNR2_BGS','TSNR2_GPBDARK','TSNR2_GPBBRIGHT','TSNR2_GPBBACKUP','ELG_EFFTIME_DARK','BGS_EFFTIME_BRIGHT','LYA_EFFTIME_DARK','GPB_EFFTIME_DARK','GPB_EFFTIME_BRIGHT','GPB_EFFTIME_BACKUP','TRANSPARENCY_GFA','SEEING_GFA','FIBER_FRACFLUX_GFA','FIBER_FRACFLUX_ELG_GFA','FIBER_FRACFLUX_BGS_GFA','FIBERFAC_GFA','FIBERFAC_ELG_GFA','FIBERFAC_BGS_GFA','AIRMASS_GFA','SKY_MAG_AB_GFA','SKY_MAG_G_SPEC','SKY_MAG_R_SPEC','SKY_MAG_Z_SPEC','EFFTIME_GFA','EFFTIME_DARK_GFA','EFFTIME_BRIGHT_GFA','EFFTIME_BACKUP_GFA']

    if not np.all(np.in1d(exp_summary.dtype.names,neworder)) :
        missing=~np.in1d(exp_summary.dtype.names,neworder)
        log.critical("missing keys {} in new order list".format(np.array(exp_summary.dtype.names)[missing]))
        log.error("new order list:",sorted(neworder))
        log.error("current table:",sorted(exp_summary.dtype.names))
        sys.exit(12)
    newtable=Table()
    newtable.meta=exp_summary.meta
    for k in neworder :
        if k in exp_summary.dtype.names :
            newtable[k]=exp_summary[k]
        else :
            newtable[k]=np.zeros(len(exp_summary))
    exp_summary=newtable

    return exp_summary, cam_summary

def write_summary_tables(tsnr2_expid_table,tsnr2_frame_table,output_fits_filename,output_csv_filename=None) :
    """ Writes a summary fits file.

    Args:
     tsnr2_expid_table: astropy.table.Table
     tsnr2_frame_table: astropy.table.Table
     output_fits_filename: str, output fits filename
     output_csv_filename: str, output csv filename

    Returns nothing
    """
    log = get_logger()

    hdus = fits.HDUList()
    hdus.append(fits.convenience.table_to_hdu(tsnr2_expid_table))
    hdus.append(fits.convenience.table_to_hdu(tsnr2_frame_table))

    tmpfile = output_fits_filename+'.tmp'
    hdus.writeto(tmpfile, overwrite=True)
    os.rename(tmpfile,  output_fits_filename)

    log.info('Successfully wrote {}'.format(output_fits_filename))

    # also write first table as csv
    if output_csv_filename is not None :
        for k in tsnr2_expid_table.keys() :
            if k.find("TIME")>=0 or k.find("SNR2")>=0 :
                try :
                    tsnr2_expid_table[k]=np.around(tsnr2_expid_table[k].astype(float),1)
                except ValueError as e :
                    log.warning("cannot change number of digits for col {}: {}".format(k,e))
            if k.find("SEEING")>=0 or k.find("FWHM")>=0 or k.find("FIBER_FRACFLUX")>=0 or k.find("FIBERFAC")>=0 or k.find("TRANS")>=0 or k.find("MAG")>=0 or k.find("AIRMASS")>=0 or k.find("EBV")>=0 :
                try :
                    tsnr2_expid_table[k]=np.around(tsnr2_expid_table[k].astype(float),3)
                except ValueError as e :
                    log.warning("cannot change number of digits for col {}: {}".format(k,e))
        tsnr2_expid_table.write(output_csv_filename,overwrite=True)
        log.info('Successfully wrote {}'.format(output_csv_filename))

def func(prod,night,expid,camera,recompute,alpha_only,details_dir) :
    """
    Compute TSNR for this night exposure camera (code in separate function for multiprocessing)

    Args:
        prod: str, production dir name
        night: int, night
        expid: int, expid
        camera: str, camera
        recompute: bool, recompute tsnr if true even if present in frame
        alpha_only: bool, only recompute alpha
        details_dir: str or None, save details per frame in this directory if not None

    Returns a dictionnary with NIGHT,EXPID,TILEID,EXPTIME,CAMERA, and the TSNR2 values for this camera
    """
    log = get_logger()

    cframe_filename = '{}/exposures/{}/{:08d}/cframe-{}-{:08d}.fits'.format(prod, night, expid, camera, expid)
    if not os.path.isfile(cframe_filename) :
        return None

    cframe_hdulist = fits.open(cframe_filename)
    hdr    = cframe_hdulist[0].header
    flavor = hdr['FLAVOR']
    if flavor != 'science':
        return None

    log.info("Processing {}".format(cframe_filename))

    prog   = hdr['PROGRAM']
    tileid = hdr['TILEID']

    table = None
    compute_tsnr = True

    #- check if already computed in cframe
    if "SCORES" in cframe_hdulist and not recompute:
        table = Table(cframe_hdulist["SCORES"].data)
        key = "TSNR2_ELG_"+camera[0].upper()
        if key in table.colnames :
            log.debug("Use TSNR values in cframe file")
            compute_tsnr = False

    #- check if already computed in details file
    table_output_filename = None
    if details_dir is not None and not recompute :
        table_output_filename= f'{details_dir}/{night}/{expid:08d}/tsnr-{camera}-{expid:08d}.fits'
        if os.path.isfile(table_output_filename):
            log.debug(f'Using previously generated {table_output_filename}')
            table = Table.read(table_output_filename)
            compute_tsnr = False

    #- compute tsnr
    if compute_tsnr :
        tsnr_table = compute_tsnr_values(cframe_filename,cframe_hdulist,night,expid,camera,specprod_dir=prod, alpha_only=alpha_only)

        if table is None :
            table = tsnr_table
        else :
            for k in tsnr_table.columns :
                table[k] = tsnr_table[k]

    fibermap = cframe_hdulist["FIBERMAP"].data

    table['FIBER']       = fibermap['FIBER']
    table['TARGETID']    = fibermap['TARGETID']
    table.meta['NIGHT']  = night
    table.meta['EXPID']  = expid
    table.meta['TILEID'] = tileid
    table.meta['CAMERA'] = camera
    table.meta['EXTNAME'] = 'TSNR2'

    #- Write per-expid per-camera output if requested
    if compute_tsnr and table_output_filename is not None :
        Path(os.path.dirname(table_output_filename)).mkdir(parents=True,exist_ok=True)
        tmpfile = table_output_filename +'.tmp'
        table.write(tmpfile, format='fits', overwrite=True)
        os.rename(tmpfile, table_output_filename)
        log.debug('Successfully wrote {}.'.format(table_output_filename))

    #- Append to summary.
    entry = dict()
    entry['NIGHT'] = np.int32(night)
    entry['EXPID'] = np.int32(expid)
    entry['TILEID'] = np.int32(tileid)
    entry['EXPTIME'] = np.float32(hdr['EXPTIME'])
    entry['AIRMASS'] = np.float32(hdr['AIRMASS'])
    if 'EBV' in fibermap.dtype.names :
        entry['EBV'] = np.median(fibermap["EBV"])
    else :
        entry['EBV'] = 0.
    if "ACQFWHM" in hdr :
        # FWHM of the guide star PSF, in arcseconds, measured in the initial acquisition image.
        entry['SEEING_ETC'] = np.float32(hdr['ACQFWHM'])

        log.debug('Retrieved ACQFWHM from frame hdr.')

    elif os.path.exists(findfile('etc', night=entry['NIGHT'], expid=entry['EXPID'])):
        with open(findfile('etc', night=entry['NIGHT'], expid=entry['EXPID'])) as etc_file:
            etcdata = json.load(etc_file)
        try:
            entry['SEEING_ETC'] = np.float32(etcdata['expinfo']['acq_fwhm'])
        except:
            entry['SEEING_ETC'] = np.float32(0.)

        log.debug('Retrieved ACQFWHM from etc json.')
    else :
        entry['SEEING_ETC'] = 0.

        log.debug('Failed to retrieved ACQFWHM from frame hdr.')

    ##  https://github.com/desihub/desietc/blob/main/header.md
    if "ETCTEFF" in hdr :
        entry['EFFTIME_ETC'] = np.float32(hdr['ETCTEFF'])

        log.debug('Retrieved ETCTEFF from frame hdr.')

    elif os.path.exists(findfile('etc', night=entry['NIGHT'], expid=entry['EXPID'])):
        with open(findfile('etc', night=entry['NIGHT'], expid=entry['EXPID'])) as etc_file:
            etcdata = json.load(etc_file)

        try:
            entry['EFFTIME_ETC'] = np.float32(etcdata['expinfo']['efftime'])
        except:
            entry['EFFTIME_ETC'] = np.float32(0.)

        log.debug('Retrieved ETCTEFF from etc json.')

    else:
        entry['EFFTIME_ETC'] = np.float32(0.)

        log.debug('Failed to retrieve ETCTEFF from etc json.')

    entry['CAMERA'] = camera
    for key in table.colnames:
        if key.startswith('TSNR2_'):
            #- TSNR2_{TRACER}_{BAND} -> TSNR2_{TRACER}
            short_key = '_'.join(key.split('_')[0:2])
            ok=(table[key]!=0)
            if np.sum(ok)>0 :
                entry[short_key]=np.median(table[key][ok]).astype(np.float32)
            else :
                entry[short_key]=0.
        if key.startswith('TSNR2_ALPHA'):
            entry['TSNR2_ALPHA'] = np.median(table[key]).astype(np.float32)

    #- Add information from targeting (SURVEY, GOALTYPE, FAPRGRM, FAFLAVOR, MINTFRAC, GOALTIME)
    fibermap_header = cframe_hdulist["FIBERMAP"].header
    targ_dict = {key : fibermap_header[key] for key in fibermap_header.keys()}
    targ_out = get_targ_info(targ_dict)
    for k in list(targ_out.keys()):
        entry[k] = targ_out[k]

    cframe_hdulist.close()
    return entry

def _func(arg) :
    """
    Wrapper function to TSNR values for multiprocessing
    """
    return func(**arg)

def func2(night,expid,specprod_dir) :
    """
    Wrapper function to compute_skymag for multiprocessing
    """
    log = get_logger()
    mags = compute_skymag(night,expid,specprod_dir)
    entry = {'NIGHT':night,'EXPID':expid,'SKY_MAG_G':mags[0],'SKY_MAG_R':mags[1],'SKY_MAG_Z':mags[2]}
    log.info(entry)
    return(entry)

def _func2(arg) :
    """
    Wrapper function to compute_skymag for multiprocessing
    """
    return func2(**arg)

def add_skymags_columns(exposure_table,skymags_table) :
    """
    Add sky magnitudes to exposure table
    Args :
       exposure_table, astropy.table.Table with column EXPID
       skymags_table astropy.table.Table with columns EXPID,SKY_MAG_G,SKY_MAG_R,SKY_MAG_Z, AB mags/arcsec2 in decam bands
    returns nothing (updates input exposure table)
    """
    e2i = {e:i for i,e in enumerate(skymags_table["EXPID"])}
    jj=[]
    ii=[]
    for j,e in enumerate(exposure_table["EXPID"]) :
        if e in e2i :
            jj.append(j)
            ii.append(e2i[e])
        cols=["SKY_MAG_G","SKY_MAG_R","SKY_MAG_Z"]
        for col in cols :
            if col in skymags_table.dtype.names :
                col2=col+"_SPEC"
                if col2 not in exposure_table.dtype.names :
                    exposure_table[col2] = np.zeros(len(exposure_table),dtype=float)
                exposure_table[col2][jj] = skymags_table[col][ii]


def main():
    log = get_logger()

    args=parse()
    if args.prod is None:
        args.prod = specprod_root()
    elif args.prod.find("/")<0 :
        args.prod = specprod_root(args.prod)

    if not args.outfile.endswith(".fits") :
        log.critical("Output filename '{}' is incorrect. It has to end with '.fits'.".format(args.outfile))
        sys.exit(1)

    log.info('outfile = {}'.format(args.outfile))
    if args.details_dir is not None : log.info('details-dir = {}'.format(args.details_dir))

    log.info('prod = {}'.format(args.prod))

    if args.multinode & use_mpi():
        from mpi4py import  MPI
        from desispec.parallel import default_nproc

        comm  = MPI.COMM_WORLD
        rank  = comm.Get_rank()
        size  = comm.Get_size()

        args.nproc = default_nproc

        multinode = True

        if args.update:
            log.critical('--update is not supported for the --multinode option.  Remove --update.')
            raise RuntimeError()

        if not args.recompute:
            log.critical('--recompute for the --multinode option.  Add --recompute.')
            raise RuntimeError()

        if (args.tile_completeness is not None):
            if os.path.isfile(args.tile_completeness):
                log.critical('Tile file exists.  Provide a new tile file path..')
                raise RuntimeError()

    else:
        comm  = None
        rank  = 0
        size  = 1

        multinode = False

    if args.cameras is None:
        petals  = np.arange(10).astype(str)
        cameras = [x[0] + x[1] for x in itertools.product(['b', 'r', 'z'], petals.astype(np.str))]
    else:
        cameras = args.cameras.split(',')

    if args.expids is not None:
        expids = [np.int(x) for x in args.expids.split(',')]
        add_missing = False
    else:
        expids = None
        add_missing = True

    if args.nights is None:
        dirnames = sorted(glob.glob('{}/exposures/*'.format(args.prod)))
        nights=[]
        for dirname in dirnames :
            try :
                night=int(os.path.basename(dirname))
                nights.append(night)
            except ValueError as e :
                log.warning("ignore {}".format(dirname))
    else :
        nights = parse_int_args(args.nights)

    log.info('cameras = {}'.format(cameras))
    log.info("nights = {}".format(nights))
    if expids is not None : log.info('expids = {}'.format(expids))

    efftime_config_filename = args.efftime_config
    if efftime_config_filename is None :
        efftime_config_filename  = resource_filename('desispec', 'data/tsnr/tsnr-efftime.yaml')
    with open(efftime_config_filename) as f:
        efftime_config = yaml.load(f, Loader=yaml.FullLoader)
    log.info("Eff. time scale factors = {}".format(efftime_config))

    preexisting_tsnr2_expid_table = None
    preexisting_tsnr2_frame_table = None
    if args.update and os.path.isfile(args.outfile) :
        log.info("Will append pre-existing table {}".format(args.outfile))
        preexisting_tsnr2_expid_table = Table.read(args.outfile,"TSNR2_EXPID")
        preexisting_tsnr2_frame_table = Table.read(args.outfile,"TSNR2_FRAME")


    # starting computing
    # one night at a time

    summary_rows  = list()

    def one_night(count, night, rows, tmpfilename):
        dirnames = sorted(glob.glob('{}/exposures/{}/*'.format(args.prod,night)))
        night_expids=[]
        for dirname in dirnames :
            try :
                expid=int(os.path.basename(dirname))
                night_expids.append(expid)
            except ValueError as e :
                log.warning("ignore {}".format(dirname))
        if expids is not None :
            night_expids = np.intersect1d(expids,night_expids)
            if night_expids.size == 0 :
                return
        log.info("{} {}".format(night,night_expids))

        #pool = multiprocessing.Pool(ncpu)
        func_args = []
        for expid in night_expids :
            for camera in cameras:
                func_args.append({'prod':args.prod,'night':night,'expid':expid,'camera':camera,
                                  'recompute':args.recompute,'alpha_only':args.alpha_only,'details_dir':args.details_dir})

        if args.nproc == 1 :
            for func_arg in func_args :
                entry = func(**func_arg)
                if entry is not None :
                    rows.append(entry)
        else :
            log.info("Multiprocessing with {} procs".format(args.nproc))
            pool = multiprocessing.Pool(args.nproc)
            results  =  pool.map(_func, func_args)
            for entry in results :
                if entry is not None :
                    rows.append(entry)
            pool.close()
            pool.join()

        # write result after every night.
        if len(rows)>0 :
            tsnr2_expid_table,tsnr2_frame_table = compute_summary_tables(rows,efftime_config,preexisting_tsnr2_expid_table,preexisting_tsnr2_frame_table,args.prod,add_missing=add_missing)
            write_summary_tables(tsnr2_expid_table,tsnr2_frame_table,output_fits_filename=tmpfilename)
            log.info("wrote {} entries in tmp file {}".format(len(rows),tmpfilename))

    if comm is not None:
        comm.barrier()

        nights     = comm.bcast(nights, root=0)

        inight     = np.linspace(0, len(nights), size+1, dtype=int)
        ranknights = nights[inight[rank]:inight[rank+1]]

        if len(ranknights) > 0:
            rank_summary_rows = list()

            log.info('Rank {:d} processes nights {} with nproc={}'.format(rank, ranknights, default_nproc))

            comm.barrier()

            outdir = os.path.dirname(args.outfile)
            if outdir == "" :
                outdir = "."
            logfile = outdir+'/desi_tsnr_afterburner_{:d}_{:d}_{:d}.log'.format(ranknights[0], ranknights[-1], rank)

            if os.path.isfile(logfile):
                os.unlink(logfile)

            with stdouterr_redirected(to=logfile):
                for count,night in enumerate(ranknights):
                    tmpfilename=args.outfile.replace(".fits","_tmp_{:d}.fits".format(rank))

                    one_night(count, night, rank_summary_rows, tmpfilename)

        comm.barrier()

    else:
        for count,night in enumerate(nights):
            tmpfilename=args.outfile.replace(".fits","_tmp.fits")

            one_night(count, night, summary_rows, tmpfilename)

    if (comm is None) | (rank == 0):
        log.info('Gathering TSNR tmp tables (over ranks: {}, {})'.format(multinode, size))

        tsnr2_expid = []
        tsnr2_frame = []

        for rank in range(size):
            if multinode:
                tmpfilename=args.outfile.replace('.fits', '_tmp_{:d}.fits'.format(rank))
            else:
                tmpfilename=args.outfile.replace('.fits', '_tmp.fits')

            try:
                tmp = fits.open(tmpfilename)

            except:
                log.warning('{} not found.'.format(tmpfilename))
                continue

            hdr = tmp[0].header

            tsnr2_expid.append(Table(tmp['TSNR2_EXPID'].data))
            tsnr2_frame.append(Table(tmp['TSNR2_FRAME'].data))

            # remove temporary file if successful
            if os.path.isfile(tmpfilename) :
                log.info("rm temporary file {}".format(tmpfilename))
                os.unlink(tmpfilename)

        tsnr2_expid_table = vstack(tsnr2_expid)
        tsnr2_frame_table = vstack(tsnr2_frame)

        tsnr2_expid_table.meta['EXTNAME'] = 'TSNR2_EXPID'
        tsnr2_frame_table.meta['EXTNAME'] = 'TSNR2_FRAME'

        if multinode:
            write_summary_tables(tsnr2_expid_table,tsnr2_frame_table,output_fits_filename=args.outfile.replace('.fits', '_tmp.fits'))

        # tsnr2_expid_table,tsnr2_frame_table = compute_summary_tables(summary_rows,efftime_config,preexisting_tsnr2_expid_table,preexisting_tsnr2_frame_table,args.prod,add_missing=add_missing)

        if args.skymags is not None :
            skymags_table = Table.read(args.skymags)
            add_skymags_columns(tsnr2_expid_table,skymags_table)

        if args.compute_skymags :
            skymag_rows=[]
            for count,night in enumerate(nights) :
                dirnames = sorted(glob.glob('{}/exposures/{}/*'.format(args.prod,night)))
                night_expids=[]
                for dirname in dirnames :
                    try :
                        expid=int(os.path.basename(dirname))
                        night_expids.append(expid)
                    except ValueError as e :
                        log.warning("ignore {}".format(dirname))
                if expids is not None :
                    night_expids = np.intersect1d(expids,night_expids)
                    if night_expids.size == 0 :
                        continue
                log.info("{} {}".format(night,night_expids))

                func2_args = []
                for expid in night_expids :
                    func2_args.append({'night':night,'expid':expid,'specprod_dir':args.prod})

                if args.nproc == 1 :
                    for func2_arg in func2_args :
                        entry = func2(**func2_arg)
                        if entry is not None :
                            skymag_rows.append(entry)
                else :
                    log.info("Multiprocessing with {} procs".format(args.nproc))
                    pool = multiprocessing.Pool(args.nproc)
                    results  =  pool.map(_func2, func2_args)
                    for entry in results :
                        if entry is not None :
                            skymag_rows.append(entry)
                    pool.close()
                    pool.join()

            colnames = list(skymag_rows[0].keys())
            skymags_table = Table(rows=skymag_rows, names=colnames)
            add_skymags_columns(tsnr2_expid_table,skymags_table)

        gfa_table = None

        if args.gfa_proc_dir is not None :
            try :
                gfa_table = read_gfa_data(args.gfa_proc_dir)
            except PermissionError as e :
                log.error(e)
                log.error("could not read some files in {}".format(args.gfa_proc_dir))
                args.gfa_proc_dir = None

        if args.gfa_proc_dir is not None and gfa_table is not None :
            e2i = {e:i for i,e in enumerate(gfa_table["EXPID"])}
            jj=[]
            ii=[]
            for j,e in enumerate(tsnr2_expid_table["EXPID"]) :
                if e in e2i :
                    jj.append(j)
                    ii.append(e2i[e])

            cols=["TRANSPARENCY","FWHM_ASEC","FIBER_FRACFLUX","FIBER_FRACFLUX_ELG","FIBER_FRACFLUX_BGS","FIBERFAC","FIBERFAC_ELG","FIBERFAC_BGS","SKY_MAG_AB","AIRMASS",]
            for col in cols :
                if col in gfa_table.dtype.names :
                    if col == "FWHM_ASEC" :
                        col2 = "SEEING_GFA"
                    else :
                        col2 = col+"_GFA"
                    tsnr2_expid_table[col2]=np.zeros(len(tsnr2_expid_table),dtype=float)
                    tsnr2_expid_table[col2][jj] = gfa_table[col][ii]

        if args.gfa_proc_dir is not None  and (args.skymags is not None or args.compute_skymags) :
            efftime_dark, efftime_bright, efftime_backup = compute_efftime(tsnr2_expid_table[jj])
            for col in ["EFFTIME_DARK_GFA","EFFTIME_BRIGHT_GFA","EFFTIME_BACKUP_GFA"] :
                tsnr2_expid_table[col]=np.zeros(len(tsnr2_expid_table),dtype=float)
            tsnr2_expid_table["EFFTIME_DARK_GFA"][jj]=efftime_dark
            tsnr2_expid_table["EFFTIME_BRIGHT_GFA"][jj]=efftime_bright
            tsnr2_expid_table["EFFTIME_BACKUP_GFA"][jj]=efftime_backup
            goaltype=tsnr2_expid_table["GOALTYPE"]
            tsnr2_expid_table["EFFTIME_GFA"] = tsnr2_expid_table["EFFTIME_DARK_GFA"] # default
            tsnr2_expid_table["EFFTIME_GFA"][goaltype=="bright"]=tsnr2_expid_table["EFFTIME_BRIGHT_GFA"][goaltype=="bright"]
            tsnr2_expid_table["EFFTIME_GFA"][goaltype=="backup"]=tsnr2_expid_table["EFFTIME_BACKUP_GFA"][goaltype=="backup"]

        # end of loop on nights
        if len(tsnr2_frame_table)>0 :
            write_summary_tables(tsnr2_expid_table,tsnr2_frame_table,output_fits_filename=args.outfile,output_csv_filename=args.outfile.replace(".fits",".csv"))

            # remove temporary file if successful
            if os.path.isfile(args.outfile) :
                tmpfilename=args.outfile.replace(".fits","_tmp.fits")
                if os.path.isfile(tmpfilename) :
                    log.info("rm temporary file {}".format(tmpfilename))
                    os.unlink(tmpfilename)
                tmpfilename=args.outfile.replace(".fits","_tmp.csv")
                if os.path.isfile(tmpfilename) :
                    log.info("rm temporary file {}".format(tmpfilename))
                    os.unlink(tmpfilename)
            else :
                log.error("no valid exposures added")

        if args.tile_completeness is not None :
            # reread the exposure table
            exposure_table = Table.read(args.outfile)
            new_tile_table = compute_tile_completeness_table(exposure_table,args.prod,auxiliary_table_filenames=args.aux)
            if os.path.isfile(args.tile_completeness) :
                previous_table = Table.read(args.tile_completeness)
                new_tile_table = merge_tile_completeness_table(previous_table,new_tile_table)
            new_tile_table.write(args.tile_completeness,overwrite=True)
            log.info("wrote {}".format(args.tile_completeness))

if __name__ == '__main__':
    main()
